{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d81314c0",
   "metadata": {},
   "source": [
    "# Regression modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ce2aac",
   "metadata": {},
   "source": [
    "## 1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afad0db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "pd.options.display.max_columns = 200\n",
    "pd.options.display.max_rows = 500\n",
    "pd.options.display.width = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c24bd022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>solution_concentration</th>\n",
       "      <th>polymer_mw</th>\n",
       "      <th>polymer_dispersity</th>\n",
       "      <th>hole_mobility</th>\n",
       "      <th>post_process</th>\n",
       "      <th>film_deposition_type_spin</th>\n",
       "      <th>solvent_boiling_point</th>\n",
       "      <th>blend_conjugated_polymer</th>\n",
       "      <th>insulating_polymer</th>\n",
       "      <th>substrate_pretreat_sam</th>\n",
       "      <th>solution_treatment_poor_solvent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.00</td>\n",
       "      <td>299.00</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.00</td>\n",
       "      <td>299.00</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.00</td>\n",
       "      <td>299.00</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.00</td>\n",
       "      <td>299.00</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.00</td>\n",
       "      <td>299.00</td>\n",
       "      <td>3.32</td>\n",
       "      <td>1.860000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.00</td>\n",
       "      <td>299.00</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.00</td>\n",
       "      <td>299.00</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.00</td>\n",
       "      <td>299.00</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.00</td>\n",
       "      <td>299.00</td>\n",
       "      <td>3.32</td>\n",
       "      <td>1.970000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.00</td>\n",
       "      <td>299.00</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.00</td>\n",
       "      <td>299.00</td>\n",
       "      <td>3.32</td>\n",
       "      <td>2.040000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.00</td>\n",
       "      <td>292.20</td>\n",
       "      <td>3.90</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.00</td>\n",
       "      <td>292.20</td>\n",
       "      <td>3.90</td>\n",
       "      <td>1.530000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.00</td>\n",
       "      <td>292.20</td>\n",
       "      <td>3.90</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.00</td>\n",
       "      <td>292.20</td>\n",
       "      <td>3.90</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.00</td>\n",
       "      <td>292.20</td>\n",
       "      <td>3.90</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.00</td>\n",
       "      <td>292.20</td>\n",
       "      <td>3.90</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.00</td>\n",
       "      <td>292.20</td>\n",
       "      <td>3.90</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.00</td>\n",
       "      <td>292.20</td>\n",
       "      <td>3.90</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.00</td>\n",
       "      <td>292.20</td>\n",
       "      <td>3.90</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.00</td>\n",
       "      <td>501.00</td>\n",
       "      <td>4.55</td>\n",
       "      <td>6.850000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.00</td>\n",
       "      <td>501.00</td>\n",
       "      <td>4.55</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.00</td>\n",
       "      <td>501.00</td>\n",
       "      <td>4.55</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.00</td>\n",
       "      <td>501.00</td>\n",
       "      <td>4.55</td>\n",
       "      <td>7.950000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5.00</td>\n",
       "      <td>501.00</td>\n",
       "      <td>4.55</td>\n",
       "      <td>7.850000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.00</td>\n",
       "      <td>501.00</td>\n",
       "      <td>4.55</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.00</td>\n",
       "      <td>501.00</td>\n",
       "      <td>4.55</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.00</td>\n",
       "      <td>501.00</td>\n",
       "      <td>4.55</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.00</td>\n",
       "      <td>501.00</td>\n",
       "      <td>4.55</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5.00</td>\n",
       "      <td>501.00</td>\n",
       "      <td>4.55</td>\n",
       "      <td>2.650000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5.00</td>\n",
       "      <td>501.00</td>\n",
       "      <td>4.55</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4.00</td>\n",
       "      <td>199.00</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.160000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>180.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4.00</td>\n",
       "      <td>199.00</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.390000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>180.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4.00</td>\n",
       "      <td>199.00</td>\n",
       "      <td>3.62</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>180.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4.00</td>\n",
       "      <td>199.00</td>\n",
       "      <td>3.62</td>\n",
       "      <td>6.760000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>180.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>4.00</td>\n",
       "      <td>199.00</td>\n",
       "      <td>3.62</td>\n",
       "      <td>2.570000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>180.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4.00</td>\n",
       "      <td>199.00</td>\n",
       "      <td>3.62</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>180.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4.00</td>\n",
       "      <td>199.00</td>\n",
       "      <td>3.62</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>180.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4.00</td>\n",
       "      <td>199.00</td>\n",
       "      <td>3.62</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>180.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3.00</td>\n",
       "      <td>290.00</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.048400</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>180.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3.00</td>\n",
       "      <td>290.00</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.181200</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>180.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>7.00</td>\n",
       "      <td>290.00</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.090100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>180.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>7.00</td>\n",
       "      <td>290.00</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.064100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>180.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>6.50</td>\n",
       "      <td>100.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.60</td>\n",
       "      <td>279.00</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.60</td>\n",
       "      <td>279.00</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.50</td>\n",
       "      <td>102.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.75</td>\n",
       "      <td>102.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.00</td>\n",
       "      <td>102.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2.00</td>\n",
       "      <td>102.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>5.00</td>\n",
       "      <td>102.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.50</td>\n",
       "      <td>102.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.75</td>\n",
       "      <td>102.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1.00</td>\n",
       "      <td>102.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2.00</td>\n",
       "      <td>102.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>5.00</td>\n",
       "      <td>102.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>5.00</td>\n",
       "      <td>104.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>7.00</td>\n",
       "      <td>104.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>8.50</td>\n",
       "      <td>104.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>10.00</td>\n",
       "      <td>104.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>12.00</td>\n",
       "      <td>104.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>14.00</td>\n",
       "      <td>104.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>16.00</td>\n",
       "      <td>104.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>18.00</td>\n",
       "      <td>104.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>25.00</td>\n",
       "      <td>104.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>5.00</td>\n",
       "      <td>104.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>7.00</td>\n",
       "      <td>104.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>8.50</td>\n",
       "      <td>104.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>10.00</td>\n",
       "      <td>104.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>12.00</td>\n",
       "      <td>104.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>14.00</td>\n",
       "      <td>104.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>16.00</td>\n",
       "      <td>104.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>18.00</td>\n",
       "      <td>104.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>25.00</td>\n",
       "      <td>104.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>3.00</td>\n",
       "      <td>104.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>5.00</td>\n",
       "      <td>104.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>7.00</td>\n",
       "      <td>104.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>8.50</td>\n",
       "      <td>104.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>10.00</td>\n",
       "      <td>104.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>12.00</td>\n",
       "      <td>104.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>14.00</td>\n",
       "      <td>104.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>16.00</td>\n",
       "      <td>104.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>18.00</td>\n",
       "      <td>104.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>25.00</td>\n",
       "      <td>104.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.095000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>3.00</td>\n",
       "      <td>104.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>5.00</td>\n",
       "      <td>104.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>7.00</td>\n",
       "      <td>104.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>10.00</td>\n",
       "      <td>104.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>12.00</td>\n",
       "      <td>104.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>14.00</td>\n",
       "      <td>104.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>18.00</td>\n",
       "      <td>104.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>25.00</td>\n",
       "      <td>104.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>3.00</td>\n",
       "      <td>292.00</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.336000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>4.00</td>\n",
       "      <td>292.00</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>5.00</td>\n",
       "      <td>292.00</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>6.00</td>\n",
       "      <td>292.00</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.442000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>8.00</td>\n",
       "      <td>292.00</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.397000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5.00</td>\n",
       "      <td>255.00</td>\n",
       "      <td>2.70</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>180.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>10.00</td>\n",
       "      <td>193.50</td>\n",
       "      <td>3.87</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>180.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>10.00</td>\n",
       "      <td>193.50</td>\n",
       "      <td>3.87</td>\n",
       "      <td>1.230000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>180.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>10.00</td>\n",
       "      <td>193.50</td>\n",
       "      <td>3.87</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>180.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>10.00</td>\n",
       "      <td>193.50</td>\n",
       "      <td>3.87</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>180.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>8.00</td>\n",
       "      <td>54.79</td>\n",
       "      <td>2.73</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>8.00</td>\n",
       "      <td>54.79</td>\n",
       "      <td>2.73</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>12.00</td>\n",
       "      <td>54.79</td>\n",
       "      <td>2.73</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>12.00</td>\n",
       "      <td>54.79</td>\n",
       "      <td>2.73</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>27.00</td>\n",
       "      <td>54.79</td>\n",
       "      <td>2.73</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>27.00</td>\n",
       "      <td>54.79</td>\n",
       "      <td>2.73</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>4.00</td>\n",
       "      <td>250.00</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>180.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2.00</td>\n",
       "      <td>204.00</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.042816</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>6.00</td>\n",
       "      <td>204.00</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.113931</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>10.00</td>\n",
       "      <td>204.00</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.061766</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>5.00</td>\n",
       "      <td>204.00</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>5.00</td>\n",
       "      <td>292.00</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>5.00</td>\n",
       "      <td>204.00</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.077000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>5.00</td>\n",
       "      <td>110.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>5.00</td>\n",
       "      <td>152.00</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>5.00</td>\n",
       "      <td>292.00</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>5.00</td>\n",
       "      <td>204.00</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.187177</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>5.00</td>\n",
       "      <td>204.00</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.190529</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>5.00</td>\n",
       "      <td>204.00</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.180283</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>5.00</td>\n",
       "      <td>204.00</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.159097</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>5.00</td>\n",
       "      <td>204.00</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.129223</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>5.00</td>\n",
       "      <td>292.00</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.143917</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>5.00</td>\n",
       "      <td>292.00</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.176246</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>5.00</td>\n",
       "      <td>292.00</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.174302</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>5.00</td>\n",
       "      <td>292.00</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.092925</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>5.00</td>\n",
       "      <td>292.00</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.074403</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>5.00</td>\n",
       "      <td>292.00</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.124165</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>5.00</td>\n",
       "      <td>292.00</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.370376</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>5.00</td>\n",
       "      <td>292.00</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.319754</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>5.00</td>\n",
       "      <td>292.00</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.257338</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>5.00</td>\n",
       "      <td>292.00</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.193502</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2.00</td>\n",
       "      <td>204.00</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.012535</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>4.00</td>\n",
       "      <td>204.00</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.038333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>6.00</td>\n",
       "      <td>204.00</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.101182</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>7.00</td>\n",
       "      <td>204.00</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.198601</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>8.00</td>\n",
       "      <td>204.00</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.163842</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>10.00</td>\n",
       "      <td>204.00</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.170187</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>2.00</td>\n",
       "      <td>110.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>4.00</td>\n",
       "      <td>110.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.007139</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.00</td>\n",
       "      <td>110.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.037412</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>8.00</td>\n",
       "      <td>110.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.072672</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>9.00</td>\n",
       "      <td>110.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.063779</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>10.00</td>\n",
       "      <td>110.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.027642</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>12.00</td>\n",
       "      <td>110.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.046912</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2.00</td>\n",
       "      <td>204.00</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.011943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>4.00</td>\n",
       "      <td>204.00</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.042120</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.00</td>\n",
       "      <td>204.00</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.148004</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>7.00</td>\n",
       "      <td>204.00</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.111808</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>8.00</td>\n",
       "      <td>204.00</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.163626</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>10.00</td>\n",
       "      <td>204.00</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.141648</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     solution_concentration  polymer_mw  polymer_dispersity  hole_mobility  post_process  film_deposition_type_spin  solvent_boiling_point  blend_conjugated_polymer  insulating_polymer  substrate_pretreat_sam  solution_treatment_poor_solvent\n",
       "0                      4.00      299.00                3.32       0.110000             1                          1                  132.0                         0                   0                       0                                0\n",
       "1                      4.00      299.00                3.32       0.290000             1                          1                  132.0                         0                   0                       1                                0\n",
       "2                      4.00      299.00                3.32       0.230000             1                          1                  132.0                         0                   0                       1                                0\n",
       "3                      4.00      299.00                3.32       0.730000             1                          1                  132.0                         0                   0                       1                                0\n",
       "4                      4.00      299.00                3.32       1.860000             1                          1                  132.0                         0                   0                       1                                0\n",
       "5                      4.00      299.00                3.32       0.210000             1                          1                  132.0                         0                   0                       1                                0\n",
       "6                      4.00      299.00                3.32       0.340000             1                          1                  132.0                         0                   0                       1                                0\n",
       "7                      4.00      299.00                3.32       0.240000             1                          1                  132.0                         0                   0                       1                                0\n",
       "8                      4.00      299.00                3.32       1.970000             1                          1                  132.0                         0                   0                       1                                0\n",
       "9                      4.00      299.00                3.32       0.690000             1                          1                  132.0                         0                   0                       1                                0\n",
       "10                     4.00      299.00                3.32       2.040000             1                          1                  132.0                         0                   0                       1                                0\n",
       "11                     5.00      292.20                3.90       0.810000             1                          1                   62.0                         0                   0                       0                                0\n",
       "12                     5.00      292.20                3.90       1.530000             1                          1                   62.0                         0                   1                       0                                0\n",
       "13                     5.00      292.20                3.90       0.900000             1                          1                   62.0                         0                   1                       0                                0\n",
       "14                     5.00      292.20                3.90       1.100000             1                          1                   62.0                         0                   1                       0                                0\n",
       "15                     5.00      292.20                3.90       1.250000             1                          1                   62.0                         0                   1                       0                                0\n",
       "16                     5.00      292.20                3.90       1.300000             1                          1                   62.0                         0                   1                       0                                0\n",
       "17                     5.00      292.20                3.90       1.250000             1                          1                   62.0                         0                   1                       0                                0\n",
       "18                     5.00      292.20                3.90       0.900000             1                          1                   62.0                         0                   1                       0                                0\n",
       "19                     5.00      292.20                3.90       0.600000             1                          1                   62.0                         0                   1                       0                                0\n",
       "20                     5.00      501.00                4.55       6.850000             1                          1                  132.0                         0                   0                       1                                0\n",
       "21                     5.00      501.00                4.55       7.250000             1                          1                  132.0                         0                   0                       1                                0\n",
       "22                     5.00      501.00                4.55       5.750000             1                          1                  132.0                         0                   0                       1                                0\n",
       "23                     5.00      501.00                4.55       7.950000             1                          1                  132.0                         0                   0                       1                                0\n",
       "24                     5.00      501.00                4.55       7.850000             1                          1                  132.0                         0                   0                       1                                0\n",
       "25                     5.00      501.00                4.55       0.150000             1                          1                  132.0                         0                   0                       1                                0\n",
       "26                     5.00      501.00                4.55       2.100000             1                          1                  132.0                         0                   0                       1                                0\n",
       "27                     5.00      501.00                4.55       9.000000             1                          1                  132.0                         0                   0                       1                                0\n",
       "28                     5.00      501.00                4.55       4.400000             1                          0                  132.0                         0                   0                       1                                0\n",
       "29                     5.00      501.00                4.55       2.650000             1                          0                  132.0                         0                   0                       1                                0\n",
       "30                     5.00      501.00                4.55       3.500000             1                          1                  132.0                         0                   0                       1                                0\n",
       "31                     4.00      199.00                3.62       1.160000             1                          1                  180.1                         0                   0                       1                                0\n",
       "32                     4.00      199.00                3.62       3.390000             1                          1                  180.1                         0                   1                       1                                0\n",
       "33                     4.00      199.00                3.62       5.800000             1                          1                  180.1                         0                   1                       1                                0\n",
       "34                     4.00      199.00                3.62       6.760000             1                          1                  180.1                         0                   1                       1                                0\n",
       "35                     4.00      199.00                3.62       2.570000             1                          1                  180.1                         0                   1                       1                                0\n",
       "36                     4.00      199.00                3.62       6.000000             1                          1                  180.1                         0                   1                       1                                0\n",
       "37                     4.00      199.00                3.62       5.000000             1                          1                  180.1                         0                   1                       1                                0\n",
       "38                     4.00      199.00                3.62       4.000000             1                          1                  180.1                         0                   1                       1                                0\n",
       "39                     3.00      290.00                2.03       0.048400             1                          1                  180.1                         0                   0                       1                                0\n",
       "40                     3.00      290.00                2.03       0.181200             1                          1                  180.1                         0                   0                       1                                0\n",
       "41                     7.00      290.00                2.03       0.090100             1                          1                  180.1                         0                   0                       1                                0\n",
       "42                     7.00      290.00                2.03       0.064100             1                          1                  180.1                         0                   0                       1                                0\n",
       "43                     6.50      100.00                3.00       0.200000             1                          1                   62.0                         0                   0                       0                                0\n",
       "44                     1.60      279.00                3.65       0.090000             1                          1                   62.0                         0                   0                       1                                0\n",
       "45                     1.60      279.00                3.65       0.140000             1                          1                   62.0                         0                   0                       1                                1\n",
       "46                     0.50      102.00                2.00       0.000150             1                          0                   62.0                         0                   0                       1                                0\n",
       "47                     0.75      102.00                2.00       0.020000             1                          0                   62.0                         0                   0                       1                                0\n",
       "48                     1.00      102.00                2.00       0.060000             1                          0                   62.0                         0                   0                       1                                0\n",
       "49                     2.00      102.00                2.00       0.150000             1                          0                   62.0                         0                   0                       1                                0\n",
       "50                     5.00      102.00                2.00       0.450000             1                          0                   62.0                         0                   0                       1                                0\n",
       "51                     0.50      102.00                2.00       0.000450             1                          0                   62.0                         0                   0                       1                                0\n",
       "52                     0.75      102.00                2.00       0.450000             1                          0                   62.0                         0                   0                       1                                0\n",
       "53                     1.00      102.00                2.00       0.200000             1                          0                   62.0                         0                   0                       1                                0\n",
       "54                     2.00      102.00                2.00       0.800000             1                          0                   62.0                         0                   0                       1                                0\n",
       "55                     5.00      102.00                2.00       0.500000             1                          0                   62.0                         0                   0                       1                                0\n",
       "56                     5.00      104.00                5.20       0.100000             1                          0                   62.0                         0                   0                       1                                0\n",
       "57                     7.00      104.00                5.20       0.170000             1                          0                   62.0                         0                   0                       1                                0\n",
       "58                     8.50      104.00                5.20       0.150000             1                          0                   62.0                         0                   0                       1                                0\n",
       "59                    10.00      104.00                5.20       0.280000             1                          0                   62.0                         0                   0                       1                                0\n",
       "60                    12.00      104.00                5.20       0.200000             1                          0                   62.0                         0                   0                       1                                0\n",
       "61                    14.00      104.00                5.20       0.290000             1                          0                   62.0                         0                   0                       1                                0\n",
       "62                    16.00      104.00                5.20       0.325000             1                          0                   62.0                         0                   0                       1                                0\n",
       "63                    18.00      104.00                5.20       0.360000             1                          0                   62.0                         0                   0                       1                                0\n",
       "64                    25.00      104.00                5.20       0.400000             1                          0                   62.0                         0                   0                       1                                0\n",
       "65                     5.00      104.00                5.20       0.180000             1                          0                   62.0                         0                   0                       1                                0\n",
       "66                     7.00      104.00                5.20       0.280000             1                          0                   62.0                         0                   0                       1                                0\n",
       "67                     8.50      104.00                5.20       0.230000             1                          0                   62.0                         0                   0                       1                                0\n",
       "68                    10.00      104.00                5.20       0.315000             1                          0                   62.0                         0                   0                       1                                0\n",
       "69                    12.00      104.00                5.20       0.180000             1                          0                   62.0                         0                   0                       1                                0\n",
       "70                    14.00      104.00                5.20       0.280000             1                          0                   62.0                         0                   0                       1                                0\n",
       "71                    16.00      104.00                5.20       0.300000             1                          0                   62.0                         0                   0                       1                                0\n",
       "72                    18.00      104.00                5.20       0.280000             1                          0                   62.0                         0                   0                       1                                0\n",
       "73                    25.00      104.00                5.20       0.275000             1                          0                   62.0                         0                   0                       1                                0\n",
       "74                     3.00      104.00                5.20       0.080000             1                          0                   62.0                         0                   0                       1                                0\n",
       "75                     5.00      104.00                5.20       0.125000             1                          0                   62.0                         0                   0                       1                                0\n",
       "76                     7.00      104.00                5.20       0.080000             1                          0                   62.0                         0                   0                       1                                0\n",
       "77                     8.50      104.00                5.20       0.080000             1                          0                   62.0                         0                   0                       1                                0\n",
       "78                    10.00      104.00                5.20       0.080000             1                          0                   62.0                         0                   0                       1                                0\n",
       "79                    12.00      104.00                5.20       0.130000             1                          0                   62.0                         0                   0                       1                                0\n",
       "80                    14.00      104.00                5.20       0.125000             1                          0                   62.0                         0                   0                       1                                0\n",
       "81                    16.00      104.00                5.20       0.050000             1                          0                   62.0                         0                   0                       1                                0\n",
       "82                    18.00      104.00                5.20       0.075000             1                          0                   62.0                         0                   0                       1                                0\n",
       "83                    25.00      104.00                5.20       0.095000             1                          0                   62.0                         0                   0                       1                                0\n",
       "84                     3.00      104.00                5.20       0.055000             1                          0                   62.0                         0                   0                       1                                0\n",
       "85                     5.00      104.00                5.20       0.325000             1                          0                   62.0                         0                   0                       1                                0\n",
       "86                     7.00      104.00                5.20       0.300000             1                          0                   62.0                         0                   0                       1                                0\n",
       "87                    10.00      104.00                5.20       0.350000             1                          0                   62.0                         0                   0                       1                                0\n",
       "88                    12.00      104.00                5.20       0.380000             1                          0                   62.0                         0                   0                       1                                0\n",
       "89                    14.00      104.00                5.20       0.425000             1                          0                   62.0                         0                   0                       1                                0\n",
       "90                    18.00      104.00                5.20       0.400000             1                          0                   62.0                         0                   0                       1                                0\n",
       "91                    25.00      104.00                5.20       0.300000             1                          0                   62.0                         0                   0                       1                                0\n",
       "92                     3.00      292.00                2.03       0.336000             1                          0                  132.0                         0                   0                       1                                0\n",
       "93                     4.00      292.00                2.03       0.401000             1                          0                  132.0                         0                   0                       1                                0\n",
       "94                     5.00      292.00                2.03       0.560000             1                          0                  132.0                         0                   0                       1                                0\n",
       "95                     6.00      292.00                2.03       0.442000             1                          0                  132.0                         0                   0                       1                                0\n",
       "96                     8.00      292.00                2.03       0.397000             1                          0                  132.0                         0                   0                       1                                0\n",
       "97                     5.00      255.00                2.70       0.800000             0                          1                  180.1                         0                   0                       1                                0\n",
       "98                    10.00      193.50                3.87       0.470000             1                          1                  180.1                         0                   0                       0                                0\n",
       "99                    10.00      193.50                3.87       1.230000             1                          1                  180.1                         0                   0                       0                                0\n",
       "100                   10.00      193.50                3.87       0.930000             1                          1                  180.1                         0                   0                       0                                0\n",
       "101                   10.00      193.50                3.87       1.360000             1                          1                  180.1                         0                   0                       0                                0\n",
       "102                    8.00       54.79                2.73       0.160000             0                          0                   62.0                         0                   0                       1                                0\n",
       "103                    8.00       54.79                2.73       0.320000             0                          0                   62.0                         0                   0                       1                                0\n",
       "104                   12.00       54.79                2.73       0.240000             0                          0                   62.0                         0                   0                       1                                0\n",
       "105                   12.00       54.79                2.73       0.270000             0                          0                   62.0                         0                   0                       1                                0\n",
       "106                   27.00       54.79                2.73       0.250000             0                          0                   62.0                         0                   0                       1                                0\n",
       "107                   27.00       54.79                2.73       0.200000             0                          0                   62.0                         0                   0                       1                                0\n",
       "108                    4.00      250.00                3.67       0.800000             1                          1                  180.1                         0                   0                       1                                0\n",
       "109                    2.00      204.00                3.10       0.042816             1                          0                  132.0                         0                   0                       0                                0\n",
       "110                    6.00      204.00                3.10       0.113931             1                          0                  132.0                         0                   0                       0                                0\n",
       "111                   10.00      204.00                3.10       0.061766             1                          0                  132.0                         0                   0                       0                                0\n",
       "112                    5.00      204.00                3.10       0.220000             1                          0                  132.0                         0                   0                       0                                0\n",
       "113                    5.00      292.00                2.03       0.105000             1                          0                  132.0                         0                   0                       0                                0\n",
       "114                    5.00      204.00                3.10       0.077000             1                          0                  132.0                         0                   0                       0                                0\n",
       "115                    5.00      110.00                2.50       0.052000             1                          0                  132.0                         0                   0                       0                                0\n",
       "116                    5.00      152.00                2.76       0.047000             1                          0                  132.0                         0                   0                       0                                0\n",
       "117                    5.00      292.00                2.03       0.104000             1                          0                  132.0                         0                   0                       0                                0\n",
       "118                    5.00      204.00                3.10       0.187177             1                          0                  132.0                         0                   1                       1                                0\n",
       "119                    5.00      204.00                3.10       0.190529             1                          0                  132.0                         0                   1                       1                                0\n",
       "120                    5.00      204.00                3.10       0.180283             1                          0                  132.0                         0                   1                       1                                0\n",
       "121                    5.00      204.00                3.10       0.159097             1                          0                  132.0                         0                   1                       1                                0\n",
       "122                    5.00      204.00                3.10       0.129223             1                          0                  132.0                         0                   0                       1                                0\n",
       "123                    5.00      292.00                2.03       0.143917             1                          0                  132.0                         0                   1                       0                                0\n",
       "124                    5.00      292.00                2.03       0.176246             1                          0                  132.0                         0                   1                       0                                0\n",
       "125                    5.00      292.00                2.03       0.174302             1                          0                  132.0                         0                   1                       0                                0\n",
       "126                    5.00      292.00                2.03       0.092925             1                          0                  132.0                         0                   1                       0                                0\n",
       "127                    5.00      292.00                2.03       0.074403             1                          0                  132.0                         0                   0                       0                                0\n",
       "128                    5.00      292.00                2.03       0.124165             1                          0                  132.0                         0                   1                       1                                0\n",
       "129                    5.00      292.00                2.03       0.370376             1                          0                  132.0                         0                   1                       1                                0\n",
       "130                    5.00      292.00                2.03       0.319754             1                          0                  132.0                         0                   1                       1                                0\n",
       "131                    5.00      292.00                2.03       0.257338             1                          0                  132.0                         0                   1                       1                                0\n",
       "132                    5.00      292.00                2.03       0.193502             1                          0                  132.0                         0                   0                       1                                0\n",
       "133                    2.00      204.00                3.10       0.012535             1                          0                  132.0                         0                   0                       0                                0\n",
       "134                    4.00      204.00                3.10       0.038333             1                          0                  132.0                         0                   0                       0                                0\n",
       "135                    6.00      204.00                3.10       0.101182             1                          0                  132.0                         0                   0                       0                                0\n",
       "136                    7.00      204.00                3.10       0.198601             1                          0                  132.0                         0                   0                       0                                0\n",
       "137                    8.00      204.00                3.10       0.163842             1                          0                  132.0                         0                   0                       0                                0\n",
       "138                   10.00      204.00                3.10       0.170187             1                          0                  132.0                         0                   0                       0                                0\n",
       "139                    2.00      110.00                2.50       0.000412             1                          0                  132.0                         0                   0                       0                                0\n",
       "140                    4.00      110.00                2.50       0.007139             1                          0                  132.0                         0                   0                       0                                0\n",
       "141                    6.00      110.00                2.50       0.037412             1                          0                  132.0                         0                   0                       0                                0\n",
       "142                    8.00      110.00                2.50       0.072672             1                          0                  132.0                         0                   0                       0                                0\n",
       "143                    9.00      110.00                2.50       0.063779             1                          0                  132.0                         0                   0                       0                                0\n",
       "144                   10.00      110.00                2.50       0.027642             1                          0                  132.0                         0                   0                       0                                0\n",
       "145                   12.00      110.00                2.50       0.046912             1                          0                  132.0                         0                   0                       0                                0\n",
       "146                    2.00      204.00                3.10       0.011943             1                          0                  132.0                         0                   0                       1                                0\n",
       "147                    4.00      204.00                3.10       0.042120             1                          0                  132.0                         0                   0                       1                                0\n",
       "148                    6.00      204.00                3.10       0.148004             1                          0                  132.0                         0                   0                       1                                0\n",
       "149                    7.00      204.00                3.10       0.111808             1                          0                  132.0                         0                   0                       1                                0\n",
       "150                    8.00      204.00                3.10       0.163626             1                          0                  132.0                         0                   0                       1                                0\n",
       "151                   10.00      204.00                3.10       0.141648             1                          0                  132.0                         0                   0                       1                                0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DPP_DTT_df = pd.read_csv(\"combined3_df_DPP_DTT_step_revised_remove_delta_others_plus_MGC_remove.csv\")\n",
    "DPP_DTT_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc52a206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['solution_concentration',\n",
       " 'polymer_mw',\n",
       " 'polymer_dispersity',\n",
       " 'hole_mobility',\n",
       " 'post_process',\n",
       " 'film_deposition_type_spin',\n",
       " 'solvent_boiling_point',\n",
       " 'blend_conjugated_polymer',\n",
       " 'insulating_polymer',\n",
       " 'substrate_pretreat_sam',\n",
       " 'solution_treatment_poor_solvent']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DPP_DTT_df_columns = DPP_DTT_df.columns.tolist()\n",
    "DPP_DTT_df_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b4cacba",
   "metadata": {},
   "outputs": [],
   "source": [
    "DPP_DTT_Y = DPP_DTT_df[['hole_mobility']]\n",
    "DPP_DTT_X = DPP_DTT_df.drop(labels = 'hole_mobility', axis = 1)\n",
    "#DPPP_DTT_X = DPP_DTT_df.drop(labels = 'polymer_dispersity', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3287c574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² score for training set: 0.517\n",
      "R² score for test set: 0.249\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(DPP_DTT_X, DPP_DTT_Y, test_size = 0.2, random_state=42)\n",
    "LR_model = LinearRegression()\n",
    "\n",
    "LR_model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = LR_model.predict(X_train)\n",
    "y_test_pred = LR_model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"R² score for training set: {r2_train:.3f}\")\n",
    "print(f\"R² score for test set: {r2_test:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cdec9b",
   "metadata": {},
   "source": [
    "## Polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d99392e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree 1: R² train = 0.517, R² test = 0.249\n",
      "Degree 2: R² train = 0.489, R² test = -0.591\n",
      "Degree 3: R² train = 0.830, R² test = 0.302\n",
      "Degree 4: R² train = 0.829, R² test = -2729941174.148\n",
      "Degree 5: R² train = 0.830, R² test = -179137997606.146\n",
      "Degree 6: R² train = 0.830, R² test = -1768396072141.032\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize lists to store R² scores\n",
    "train_r2_scores = []\n",
    "test_r2_scores = []\n",
    "degrees = range(1, 7)\n",
    "\n",
    "# Loop through degrees 1 to 6\n",
    "for degree in degrees:\n",
    "    # Create polynomial features\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    X_test_poly = poly.transform(X_test)\n",
    "    \n",
    "    # Train the model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_poly, y_train)\n",
    "    \n",
    "    # Predict on training and test sets\n",
    "    y_train_pred = model.predict(X_train_poly)\n",
    "    y_test_pred = model.predict(X_test_poly)\n",
    "    \n",
    "    # Calculate R² scores\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Append scores to the lists\n",
    "    train_r2_scores.append(r2_train)\n",
    "    test_r2_scores.append(r2_test)\n",
    "\n",
    "# Print R² scores for each degree\n",
    "for degree, r2_train, r2_test in zip(degrees, train_r2_scores, test_r2_scores):\n",
    "    print(f\"Degree {degree}: R² train = {r2_train:.3f}, R² test = {r2_test:.3f}\")\n",
    "\n",
    "# Plot the R² scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(degrees, train_r2_scores, label='Train R²', marker='o')\n",
    "plt.plot(degrees, test_r2_scores, label='Test R²', marker='o')\n",
    "plt.xlabel('Polynomial Degree')\n",
    "plt.ylabel('R² Score')\n",
    "plt.title('R² Score vs Polynomial Degree')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c19cd8",
   "metadata": {},
   "source": [
    "## Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dee0ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha 0.1: R² train = 0.517, R² test = 0.253\n",
      "Alpha 0.2: R² train = 0.517, R² test = 0.255\n",
      "Alpha 0.3: R² train = 0.517, R² test = 0.257\n",
      "Alpha 0.4: R² train = 0.516, R² test = 0.259\n",
      "Alpha 0.5: R² train = 0.516, R² test = 0.261\n",
      "Alpha 0.6: R² train = 0.516, R² test = 0.262\n",
      "Alpha 0.7: R² train = 0.516, R² test = 0.263\n",
      "Alpha 0.8: R² train = 0.515, R² test = 0.264\n",
      "Alpha 0.9: R² train = 0.515, R² test = 0.265\n",
      "Alpha 1.0: R² train = 0.515, R² test = 0.266\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize lists to store R² scores\n",
    "train_r2_scores = []\n",
    "test_r2_scores = []\n",
    "alphas = np.arange(0.1, 1.1, 0.1)\n",
    "\n",
    "# Loop through alpha values\n",
    "for alpha in alphas:\n",
    "    # Train Ridge Regression model\n",
    "    model = Ridge(alpha=alpha)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on training and test sets\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate R² scores\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Append scores to the lists\n",
    "    train_r2_scores.append(r2_train)\n",
    "    test_r2_scores.append(r2_test)\n",
    "\n",
    "# Print R² scores for each alpha\n",
    "for alpha, r2_train, r2_test in zip(alphas, train_r2_scores, test_r2_scores):\n",
    "    print(f\"Alpha {alpha:.1f}: R² train = {r2_train:.3f}, R² test = {r2_test:.3f}\")\n",
    "\n",
    "# Plot the R² scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(alphas, train_r2_scores, label='Train R²', marker='o')\n",
    "plt.plot(alphas, test_r2_scores, label='Test R²', marker='o')\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('R² Score')\n",
    "plt.title('R² Score vs Alpha (Ridge Regression)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded9aa39",
   "metadata": {},
   "source": [
    "## Lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53339a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha 0.1: R² train = 0.450, R² test = 0.180\n",
      "Alpha 0.2: R² train = 0.423, R² test = 0.115\n",
      "Alpha 0.3: R² train = 0.410, R² test = 0.079\n",
      "Alpha 0.4: R² train = 0.391, R² test = 0.025\n",
      "Alpha 0.5: R² train = 0.366, R² test = -0.044\n",
      "Alpha 0.6: R² train = 0.352, R² test = -0.079\n",
      "Alpha 0.7: R² train = 0.350, R² test = -0.076\n",
      "Alpha 0.8: R² train = 0.348, R² test = -0.074\n",
      "Alpha 0.9: R² train = 0.347, R² test = -0.072\n",
      "Alpha 1.0: R² train = 0.347, R² test = -0.072\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize lists to store R² scores\n",
    "train_r2_scores = []\n",
    "test_r2_scores = []\n",
    "alphas = np.arange(0.1, 1.1, 0.1)\n",
    "\n",
    "# Loop through alpha values\n",
    "for alpha in alphas:\n",
    "    # Train Lasso Regression model\n",
    "    model = Lasso(alpha=alpha, max_iter=10000)  # Increased max_iter to ensure convergence\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on training and test sets\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate R² scores\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Append scores to the lists\n",
    "    train_r2_scores.append(r2_train)\n",
    "    test_r2_scores.append(r2_test)\n",
    "\n",
    "# Print R² scores for each alpha\n",
    "for alpha, r2_train, r2_test in zip(alphas, train_r2_scores, test_r2_scores):\n",
    "    print(f\"Alpha {alpha:.1f}: R² train = {r2_train:.3f}, R² test = {r2_test:.3f}\")\n",
    "\n",
    "# Plot the R² scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(alphas, train_r2_scores, label='Train R²', marker='o')\n",
    "plt.plot(alphas, test_r2_scores, label='Test R²', marker='o')\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('R² Score')\n",
    "plt.title('R² Score vs Alpha (Lasso Regression)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bca8f0",
   "metadata": {},
   "source": [
    "## Elsaticnet regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e25191c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    alpha  l1_ratio  r2_train   r2_test\n",
      "0     0.1       0.1  0.491699  0.260878\n",
      "1     0.1       0.2  0.488173  0.255454\n",
      "2     0.1       0.3  0.484090  0.248505\n",
      "3     0.1       0.4  0.479079  0.239996\n",
      "4     0.1       0.5  0.473548  0.229990\n",
      "5     0.1       0.6  0.469164  0.219263\n",
      "6     0.1       0.7  0.463850  0.206062\n",
      "7     0.1       0.8  0.460132  0.199362\n",
      "8     0.1       0.9  0.455645  0.190957\n",
      "9     0.1       1.0  0.450169  0.180359\n",
      "10    0.2       0.1  0.473974  0.229731\n",
      "11    0.2       0.2  0.465762  0.213604\n",
      "12    0.2       0.3  0.457344  0.195159\n",
      "13    0.2       0.4  0.449757  0.177857\n",
      "14    0.2       0.5  0.441968  0.161395\n",
      "15    0.2       0.6  0.432001  0.139438\n",
      "16    0.2       0.7  0.426696  0.125989\n",
      "17    0.2       0.8  0.425634  0.122594\n",
      "18    0.2       0.9  0.424454  0.118944\n",
      "19    0.2       1.0  0.423145  0.114988\n",
      "20    0.3       0.1  0.460523  0.201233\n",
      "21    0.3       0.2  0.449530  0.177424\n",
      "22    0.3       0.3  0.439948  0.155321\n",
      "23    0.3       0.4  0.428867  0.129950\n",
      "24    0.3       0.5  0.423104  0.115001\n",
      "25    0.3       0.6  0.421148  0.109248\n",
      "26    0.3       0.7  0.418914  0.102875\n",
      "27    0.3       0.8  0.416369  0.095808\n",
      "28    0.3       0.9  0.413472  0.087974\n",
      "29    0.3       1.0  0.410175  0.079252\n",
      "30    0.4       0.1  0.449890  0.177314\n",
      "31    0.4       0.2  0.437849  0.149423\n",
      "32    0.4       0.3  0.425726  0.120935\n",
      "33    0.4       0.4  0.419371  0.104281\n",
      "34    0.4       0.5  0.416373  0.095922\n",
      "35    0.4       0.6  0.412793  0.085857\n",
      "36    0.4       0.7  0.408553  0.073927\n",
      "37    0.4       0.8  0.403570  0.060029\n",
      "38    0.4       0.9  0.397700  0.043776\n",
      "39    0.4       1.0  0.390766  0.024666\n",
      "40    0.5       0.1  0.441105  0.155260\n",
      "41    0.5       0.2  0.428132  0.124288\n",
      "42    0.5       0.3  0.416859  0.096229\n",
      "43    0.5       0.4  0.412921  0.085001\n",
      "44    0.5       0.5  0.408201  0.071763\n",
      "45    0.5       0.6  0.402545  0.056092\n",
      "46    0.5       0.7  0.395754  0.037443\n",
      "47    0.5       0.8  0.387577  0.015124\n",
      "48    0.5       0.9  0.377685 -0.011777\n",
      "49    0.5       1.0  0.365649 -0.044440\n",
      "50    0.6       0.1  0.433849  0.135801\n",
      "51    0.6       0.2  0.419352  0.100752\n",
      "52    0.6       0.3  0.411444  0.079708\n",
      "53    0.6       0.4  0.406003  0.064570\n",
      "54    0.6       0.5  0.399371  0.046375\n",
      "55    0.6       0.6  0.391275  0.024375\n",
      "56    0.6       0.7  0.381354 -0.002417\n",
      "57    0.6       0.8  0.369130 -0.035312\n",
      "58    0.6       0.9  0.353958 -0.076092\n",
      "59    0.6       1.0  0.351703 -0.078713\n",
      "60    0.7       0.1  0.427507  0.118549\n",
      "61    0.7       0.2  0.411849  0.079798\n",
      "62    0.7       0.3  0.405971  0.063454\n",
      "63    0.7       0.4  0.398890  0.044127\n",
      "64    0.7       0.5  0.390126  0.020489\n",
      "65    0.7       0.6  0.379242 -0.008648\n",
      "66    0.7       0.7  0.365647 -0.044897\n",
      "67    0.7       0.8  0.352244 -0.079702\n",
      "68    0.7       0.9  0.351243 -0.077934\n",
      "69    0.7       1.0  0.350121 -0.076267\n",
      "70    0.8       0.1  0.422160  0.103864\n",
      "71    0.8       0.2  0.407568  0.066885\n",
      "72    0.8       0.3  0.400524  0.047645\n",
      "73    0.8       0.4  0.391699  0.023939\n",
      "74    0.8       0.5  0.380622 -0.005518\n",
      "75    0.8       0.6  0.366647 -0.042475\n",
      "76    0.8       0.7  0.352227 -0.079663\n",
      "77    0.8       0.8  0.351076 -0.077661\n",
      "78    0.8       0.9  0.349766 -0.075789\n",
      "79    0.8       1.0  0.348295 -0.074050\n",
      "80    0.9       0.1  0.417259  0.090264\n",
      "81    0.9       0.2  0.403557  0.054979\n",
      "82    0.9       0.3  0.395158  0.032387\n",
      "83    0.9       0.4  0.384512  0.004183\n",
      "84    0.9       0.5  0.370976 -0.031375\n",
      "85    0.9       0.6  0.353651 -0.076720\n",
      "86    0.9       0.7  0.351213 -0.077874\n",
      "87    0.9       0.8  0.349755 -0.075769\n",
      "88    0.9       0.9  0.348094 -0.073830\n",
      "89    0.9       1.0  0.346580 -0.072396\n",
      "90    1.0       0.1  0.412742  0.077651\n",
      "91    1.0       0.2  0.399682  0.043671\n",
      "92    1.0       0.3  0.389907  0.017738\n",
      "93    1.0       0.4  0.377385 -0.015026\n",
      "94    1.0       0.5  0.361275 -0.056884\n",
      "95    1.0       0.6  0.351639 -0.078579\n",
      "96    1.0       0.7  0.350084 -0.076200\n",
      "97    1.0       0.8  0.348282 -0.074025\n",
      "98    1.0       0.9  0.346580 -0.072390\n",
      "99    1.0       1.0  0.346548 -0.072427\n",
      "Maximum Train R²:\n",
      "alpha       0.100000\n",
      "l1_ratio    0.100000\n",
      "r2_train    0.491699\n",
      "r2_test     0.260878\n",
      "Name: 0, dtype: float64\n",
      "\n",
      "Maximum Test R²:\n",
      "alpha       0.100000\n",
      "l1_ratio    0.100000\n",
      "r2_train    0.491699\n",
      "r2_test     0.260878\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize lists to store results\n",
    "results = []\n",
    "\n",
    "# Alpha and l1_ratio ranges\n",
    "alphas = np.arange(0.1, 1.1, 0.1)\n",
    "l1_ratios = np.arange(0.1, 1.1, 0.1)\n",
    "\n",
    "# Loop through alpha and l1_ratio values\n",
    "for alpha in alphas:\n",
    "    for l1_ratio in l1_ratios:\n",
    "        # Train ElasticNet Regression model\n",
    "        model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, max_iter=10000)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on training and test sets\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate R² scores\n",
    "        r2_train = r2_score(y_train, y_train_pred)\n",
    "        r2_test = r2_score(y_test, y_test_pred)\n",
    "        \n",
    "        # Append results\n",
    "        results.append({'alpha': alpha, 'l1_ratio': l1_ratio, 'r2_train': r2_train, 'r2_test': r2_test})\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Print the results\n",
    "print(results_df)\n",
    "\n",
    "# Find the row with the maximum R² score for training\n",
    "max_train_r2 = results_df.loc[results_df['r2_train'].idxmax()]\n",
    "print(\"Maximum Train R²:\")\n",
    "print(max_train_r2)\n",
    "\n",
    "# Find the row with the maximum R² score for testing\n",
    "max_test_r2 = results_df.loc[results_df['r2_test'].idxmax()]\n",
    "print(\"\\nMaximum Test R²:\")\n",
    "print(max_test_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5484c70",
   "metadata": {},
   "source": [
    "## Support Vector Regression (SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91a74394",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    C  epsilon  r2_train   r2_test\n",
      "0   1      0.1  0.487939  0.124502\n",
      "1   1      0.2  0.493945  0.160011\n",
      "2   1      0.3  0.489299  0.173830\n",
      "3   1      0.4  0.483655  0.188292\n",
      "4   1      0.5  0.495589  0.211614\n",
      "5   1      0.6  0.501118  0.172443\n",
      "6   1      0.7  0.502078  0.140039\n",
      "7   1      0.8  0.497715  0.101907\n",
      "8   1      0.9  0.487616  0.059972\n",
      "9   1      1.0  0.472084  0.000547\n",
      "10  1      1.1  0.451412 -0.076288\n",
      "11  2      0.1  0.540898  0.073092\n",
      "12  2      0.2  0.555771  0.066491\n",
      "13  2      0.3  0.559628  0.038235\n",
      "14  2      0.4  0.572573  0.055999\n",
      "15  2      0.5  0.572680  0.047542\n",
      "16  2      0.6  0.573089  0.066045\n",
      "17  2      0.7  0.579719  0.077660\n",
      "18  2      0.8  0.577127  0.043123\n",
      "19  2      0.9  0.570222 -0.001502\n",
      "20  2      1.0  0.559294 -0.054660\n",
      "21  2      1.1  0.533803 -0.137788\n",
      "22  3      0.1  0.567783 -0.048567\n",
      "23  3      0.2  0.573168 -0.014348\n",
      "24  3      0.3  0.577773  0.013426\n",
      "25  3      0.4  0.581449  0.045125\n",
      "26  3      0.5  0.581515  0.067181\n",
      "27  3      0.6  0.586213  0.078565\n",
      "28  3      0.7  0.591577  0.046996\n",
      "29  3      0.8  0.589838  0.013141\n",
      "30  3      0.9  0.584181  0.000077\n",
      "31  3      1.0  0.573945 -0.026514\n",
      "32  3      1.1  0.553281 -0.115463\n",
      "33  4      0.1  0.583232 -0.062836\n",
      "34  4      0.2  0.578927 -0.104781\n",
      "35  4      0.3  0.592351 -0.106851\n",
      "36  4      0.4  0.591033 -0.141065\n",
      "37  4      0.5  0.586195 -0.181596\n",
      "38  4      0.6  0.592011 -0.178785\n",
      "39  4      0.7  0.601209 -0.148469\n",
      "40  4      0.8  0.601557 -0.131566\n",
      "41  4      0.9  0.600285 -0.114730\n",
      "42  4      1.0  0.587407 -0.112188\n",
      "43  4      1.1  0.559506 -0.148652\n",
      "44  5      0.1  0.586588 -0.052849\n",
      "45  5      0.2  0.591984 -0.073735\n",
      "46  5      0.3  0.593325 -0.098626\n",
      "47  5      0.4  0.591837 -0.138588\n",
      "48  5      0.5  0.592197 -0.168873\n",
      "49  5      0.6  0.603583 -0.155530\n",
      "50  5      0.7  0.608321 -0.133359\n",
      "51  5      0.8  0.605026 -0.125788\n",
      "52  5      0.9  0.599688 -0.109123\n",
      "53  5      1.0  0.586083 -0.111204\n",
      "54  5      1.1  0.568440 -0.133664\n",
      "55  6      0.1  0.596079 -0.031421\n",
      "56  6      0.2  0.601493 -0.049929\n",
      "57  6      0.3  0.600592 -0.081830\n",
      "58  6      0.4  0.598415 -0.123549\n",
      "59  6      0.5  0.601927 -0.147435\n",
      "60  6      0.6  0.609029 -0.143876\n",
      "61  6      0.7  0.612765 -0.123747\n",
      "62  6      0.8  0.607546 -0.117886\n",
      "63  6      0.9  0.598798 -0.105093\n",
      "64  6      1.0  0.592952 -0.097167\n",
      "65  6      1.1  0.579158 -0.112245\n",
      "\n",
      "Maximum Train R²:\n",
      "C           6.000000\n",
      "epsilon     0.700000\n",
      "r2_train    0.612765\n",
      "r2_test    -0.123747\n",
      "Name: 61, dtype: float64\n",
      "\n",
      "Maximum Test R²:\n",
      "C           1.000000\n",
      "epsilon     0.500000\n",
      "r2_train    0.495589\n",
      "r2_test     0.211614\n",
      "Name: 4, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Initialize lists to store results\n",
    "results = []\n",
    "\n",
    "# Range of C and epsilon values\n",
    "C_values = np.arange(1, 7, 1)\n",
    "epsilon_values = np.arange(0.1, 1.2, 0.1)\n",
    "\n",
    "# Loop through C and epsilon values\n",
    "for C in C_values:\n",
    "    for epsilon in epsilon_values:\n",
    "        # Train SVR model\n",
    "        model = SVR(C=C, epsilon=epsilon)\n",
    "        model.fit(X_train, y_train)  # Flatten y for SVR compatibility\n",
    "        \n",
    "        # Predict on training and test sets\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate R² scores\n",
    "        r2_train = r2_score(y_train, y_train_pred)\n",
    "        r2_test = r2_score(y_test, y_test_pred)\n",
    "        \n",
    "        # Append results\n",
    "        results.append({'C': C, 'epsilon': epsilon, 'r2_train': r2_train, 'r2_test': r2_test})\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Print the results\n",
    "print(results_df)\n",
    "\n",
    "# Find the best combination for training and testing\n",
    "max_train_r2 = results_df.loc[results_df['r2_train'].idxmax()]\n",
    "max_test_r2 = results_df.loc[results_df['r2_test'].idxmax()]\n",
    "\n",
    "print(\"\\nMaximum Train R²:\")\n",
    "print(max_train_r2)\n",
    "\n",
    "print(\"\\nMaximum Test R²:\")\n",
    "print(max_test_r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd08a7e",
   "metadata": {},
   "source": [
    "## Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1e45f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² score for training set: 0.830\n",
      "R² score for test set: 0.347\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize the Decision Tree Regressor\n",
    "model = DecisionTreeRegressor()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on training and test sets\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate R² scores\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Print the R² scores\n",
    "print(f\"R² score for training set: {r2_train:.3f}\")\n",
    "print(f\"R² score for test set: {r2_test:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14feb2c8",
   "metadata": {},
   "source": [
    "## Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89496068",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'ravel'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30848\\4025085130.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Loop through n_estimators values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn_estimators\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mn_estimators_range\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# Train Random Forest Regressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Flatten y for compatibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m# Predict on training and test sets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0my_train_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6200\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6201\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6202\u001b[0m         ):\n\u001b[0;32m   6203\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6204\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'ravel'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Initialize lists to store results\n",
    "results = []\n",
    "\n",
    "# Range of n_estimators\n",
    "n_estimators_range = range(100, 401, 10)\n",
    "\n",
    "# Loop through n_estimators values\n",
    "for n_estimators in n_estimators_range:\n",
    "    # Train Random Forest Regressor\n",
    "    model = RandomForestRegressor(n_estimators=n_estimators, random_state=42)\n",
    "    model.fit(X_train, y_train.ravel())  # Flatten y for compatibility\n",
    "    \n",
    "    # Predict on training and test sets\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate R² scores\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Append results\n",
    "    results.append({'n_estimators': n_estimators, 'r2_train': r2_train, 'r2_test': r2_test})\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Print the results\n",
    "print(\"Top 10 configurations by Test R²:\")\n",
    "print(results_df.sort_values(by='r2_test', ascending=False).head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa756e55",
   "metadata": {},
   "source": [
    "## Gradient bossting regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17993859",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "C:\\Users\\Myeongyeon Lee\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 27\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m max_depth \u001b[38;5;129;01min\u001b[39;00m max_depth_range:\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# Train Gradient Boosting Regressor\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     model \u001b[38;5;241m=\u001b[39m GradientBoostingRegressor(\n\u001b[0;32m     23\u001b[0m         n_estimators\u001b[38;5;241m=\u001b[39mn_estimators,\n\u001b[0;32m     24\u001b[0m         learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate,\n\u001b[0;32m     25\u001b[0m         max_depth\u001b[38;5;241m=\u001b[39mmax_depth\n\u001b[0;32m     26\u001b[0m     )\n\u001b[1;32m---> 27\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)  \u001b[38;5;66;03m# Flatten y for compatibility\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m# Predict on training and test sets\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     y_train_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_train)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:784\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n\u001b[0;32m    783\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[1;32m--> 784\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_stages(\n\u001b[0;32m    785\u001b[0m     X_train,\n\u001b[0;32m    786\u001b[0m     y_train,\n\u001b[0;32m    787\u001b[0m     raw_predictions,\n\u001b[0;32m    788\u001b[0m     sample_weight_train,\n\u001b[0;32m    789\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rng,\n\u001b[0;32m    790\u001b[0m     X_val,\n\u001b[0;32m    791\u001b[0m     y_val,\n\u001b[0;32m    792\u001b[0m     sample_weight_val,\n\u001b[0;32m    793\u001b[0m     begin_at_stage,\n\u001b[0;32m    794\u001b[0m     monitor,\n\u001b[0;32m    795\u001b[0m )\n\u001b[0;32m    797\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[0;32m    798\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:880\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    873\u001b[0m         initial_loss \u001b[38;5;241m=\u001b[39m factor \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss(\n\u001b[0;32m    874\u001b[0m             y_true\u001b[38;5;241m=\u001b[39my_oob_masked,\n\u001b[0;32m    875\u001b[0m             raw_prediction\u001b[38;5;241m=\u001b[39mraw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    876\u001b[0m             sample_weight\u001b[38;5;241m=\u001b[39msample_weight_oob_masked,\n\u001b[0;32m    877\u001b[0m         )\n\u001b[0;32m    879\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[1;32m--> 880\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_stage(\n\u001b[0;32m    881\u001b[0m     i,\n\u001b[0;32m    882\u001b[0m     X,\n\u001b[0;32m    883\u001b[0m     y,\n\u001b[0;32m    884\u001b[0m     raw_predictions,\n\u001b[0;32m    885\u001b[0m     sample_weight,\n\u001b[0;32m    886\u001b[0m     sample_mask,\n\u001b[0;32m    887\u001b[0m     random_state,\n\u001b[0;32m    888\u001b[0m     X_csc\u001b[38;5;241m=\u001b[39mX_csc,\n\u001b[0;32m    889\u001b[0m     X_csr\u001b[38;5;241m=\u001b[39mX_csr,\n\u001b[0;32m    890\u001b[0m )\n\u001b[0;32m    892\u001b[0m \u001b[38;5;66;03m# track loss\u001b[39;00m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:490\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    487\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;241m*\u001b[39m sample_mask\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m    489\u001b[0m X \u001b[38;5;241m=\u001b[39m X_csc \u001b[38;5;28;01mif\u001b[39;00m X_csc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[1;32m--> 490\u001b[0m tree\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m    491\u001b[0m     X, neg_g_view[:, k], sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    492\u001b[0m )\n\u001b[0;32m    494\u001b[0m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[0;32m    495\u001b[0m X_for_tree_update \u001b[38;5;241m=\u001b[39m X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1377\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1349\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1350\u001b[0m \n\u001b[0;32m   1351\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1377\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m   1378\u001b[0m         X,\n\u001b[0;32m   1379\u001b[0m         y,\n\u001b[0;32m   1380\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m   1381\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[0;32m   1382\u001b[0m     )\n\u001b[0;32m   1383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize lists to store results\n",
    "results = []\n",
    "\n",
    "# Hyperparameter ranges\n",
    "n_estimators_range = range(100, 311, 10)\n",
    "learning_rate_range = np.arange(0.1, 1.1, 0.1)\n",
    "max_depth_range = range(1, 16)\n",
    "\n",
    "# Perform grid search over hyperparameters\n",
    "for n_estimators in n_estimators_range:\n",
    "    for learning_rate in learning_rate_range:\n",
    "        for max_depth in max_depth_range:\n",
    "            # Train Gradient Boosting Regressor\n",
    "            model = GradientBoostingRegressor(\n",
    "                n_estimators=n_estimators,\n",
    "                learning_rate=learning_rate,\n",
    "                max_depth=max_depth\n",
    "            )\n",
    "            model.fit(X_train, y_train)  # Flatten y for compatibility\n",
    "            \n",
    "            # Predict on training and test sets\n",
    "            y_train_pred = model.predict(X_train)\n",
    "            y_test_pred = model.predict(X_test)\n",
    "            \n",
    "            # Calculate R² scores\n",
    "            r2_train = r2_score(y_train, y_train_pred)\n",
    "            r2_test = r2_score(y_test, y_test_pred)\n",
    "            \n",
    "            # Append results\n",
    "            results.append({\n",
    "                'n_estimators': n_estimators,\n",
    "                'learning_rate': learning_rate,\n",
    "                'max_depth': max_depth,\n",
    "                'r2_train': r2_train,\n",
    "                'r2_test': r2_test\n",
    "            })\n",
    "\n",
    "# Print the top results sorted by test R²\n",
    "print(\"Top 10 configurations by Test R²:\")\n",
    "print(results_df.sort_values(by='r2_test', ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bee255f",
   "metadata": {},
   "source": [
    "## K-nearest Neighbors Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23645960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Initialize lists to store results\n",
    "results = []\n",
    "\n",
    "# Range of n_neighbors\n",
    "n_neighbors_range = range(1, 17)\n",
    "\n",
    "# Loop through n_neighbors values\n",
    "for n_neighbors in n_neighbors_range:\n",
    "    # Train K-Nearest Neighbors Regressor\n",
    "    model = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "    model.fit(X_train, y_train.ravel())  # Flatten y for compatibility\n",
    "    \n",
    "    # Predict on training and test sets\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate R² scores\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Append results\n",
    "    results.append({'n_neighbors': n_neighbors, 'r2_train': r2_train, 'r2_test': r2_test})\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Print the results\n",
    "print(\"Top configurations by Test R²:\")\n",
    "print(results_df.sort_values(by='r2_test', ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb45c82-77ff-448c-bf15-259779121e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Train k-NN model\n",
    "knn = KNeighborsRegressor(n_neighbors=9)\n",
    "knn.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate baseline performance\n",
    "baseline_r2 = r2_score(Y_test, knn.predict(X_test))\n",
    "\n",
    "# Compute permutation importance\n",
    "perm_importance = permutation_importance(knn, X_test, Y_test, n_repeats=30, random_state=42)\n",
    "\n",
    "# Display importance scores\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': DPP_DTT_X.columns,\n",
    "    'importance': perm_importance.importances_mean\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5bdc62-a675-45e8-808b-ab09547e0a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Initialize lists to store results\n",
    "results = []\n",
    "\n",
    "# Hyperparameter ranges\n",
    "n_estimators_range = range(100, 311, 10)\n",
    "learning_rate_range = np.arange(0.1, 1.1, 0.1)\n",
    "max_depth_range = range(1, 17)\n",
    "\n",
    "# Perform grid search over hyperparameters\n",
    "for n_estimators in n_estimators_range:\n",
    "    for learning_rate in learning_rate_range:\n",
    "        for max_depth in max_depth_range:\n",
    "            # Train XGBoost Regressor\n",
    "            model = XGBRegressor(\n",
    "                n_estimators=n_estimators,\n",
    "                learning_rate=learning_rate,\n",
    "                max_depth=max_depth,\n",
    "                random_state=42\n",
    "            )\n",
    "            model.fit(X_train, y_train.ravel())  # Flatten y for compatibility\n",
    "            \n",
    "            # Predict on training and test sets\n",
    "            y_train_pred = model.predict(X_train)\n",
    "            y_test_pred = model.predict(X_test)\n",
    "            \n",
    "            # Calculate R² scores\n",
    "            r2_train = r2_score(y_train, y_train_pred)\n",
    "            r2_test = r2_score(y_test, y_test_pred)\n",
    "            \n",
    "            # Append results\n",
    "            results.append({\n",
    "                'n_estimators': n_estimators,\n",
    "                'learning_rate': learning_rate,\n",
    "                'max_depth': max_depth,\n",
    "                'r2_train': r2_train,\n",
    "                'r2_test': r2_test\n",
    "            })\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Print the top 10 configurations sorted by test R²\n",
    "print(\"Top 10 configurations by Test R²:\")\n",
    "print(results_df.sort_values(by='r2_test', ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f0b3c9",
   "metadata": {},
   "source": [
    "## Adaboost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2859084d-3169-4e4f-b147-4f681f435af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Initialize lists to store results\n",
    "results = []\n",
    "\n",
    "# Hyperparameter ranges\n",
    "n_estimators_range = range(100, 311, 10)\n",
    "learning_rate_range = np.arange(0.1, 1.1, 0.1)\n",
    "max_depth_range = range(1, 17)\n",
    "\n",
    "# Perform grid search over hyperparameters\n",
    "for n_estimators in n_estimators_range:\n",
    "    for learning_rate in learning_rate_range:\n",
    "        for max_depth in max_depth_range:\n",
    "            # Define the AdaBoost model with a DecisionTreeRegressor as the base learner\n",
    "            model = AdaBoostRegressor(\n",
    "                n_estimators=n_estimators,\n",
    "                learning_rate=learning_rate,\n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            # Train the model\n",
    "            model.fit(X_train, y_train.ravel())\n",
    "            \n",
    "            # Predict on training and test sets\n",
    "            y_train_pred = model.predict(X_train)\n",
    "            y_test_pred = model.predict(X_test)\n",
    "            \n",
    "            # Calculate R² scores\n",
    "            r2_train = r2_score(y_train, y_train_pred)\n",
    "            r2_test = r2_score(y_test, y_test_pred)\n",
    "            \n",
    "            # Append results\n",
    "            results.append({\n",
    "                'n_estimators': n_estimators,\n",
    "                'learning_rate': learning_rate,\n",
    "                'max_depth': max_depth,\n",
    "                'r2_train': r2_train,\n",
    "                'r2_test': r2_test\n",
    "            })\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Print the top 10 configurations sorted by test R²\n",
    "\n",
    "print(\"Top 10 configurations by Test R²:\")\n",
    "print(results_df.sort_values(by='r2_test', ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43219ea-f07f-4ad5-8bee-23b74d2a252f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Example dataset (replace with your actual dataset)\n",
    "\n",
    "# Train AdaBoost Regressor\n",
    "model = AdaBoostRegressor(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': DPP_DTT_X.columns,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort features by importance (descending order)\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print the sorted feature importances\n",
    "print(\"Feature Importance (Descending Order):\")\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b55c06-e61c-40fe-bae4-e93647fffc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "DPP_DTT_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b5573b-2b4f-4fcb-996e-46c57c3f58c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Correlation Matrix:\")\n",
    "correlation_matrix = DPP_DTT_X.corr()\n",
    "print(correlation_matrix)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=False, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation Matrix of Independent Variables\")\n",
    "plt.show()\n",
    "plt.savefig(fname='DPP_DTT_revised_matrix.tif', format='tiff', dpi=300)\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data['Feature'] = DPP_DTT_X.columns\n",
    "vif_data['VIF'] = [\n",
    "    variance_inflation_factor(DPP_DTT_X, i + 1) for i in range(DPP_DTT_X.shape[1])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d65b6c-9573-4011-b3c0-b8a5e4feff91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Range of K-Fold splits to evaluate\n",
    "k_values = range(2, 11)  # From K=2 to K=10 (K=1 is invalid for cross-validation)\n",
    "\n",
    "# Lists to store results for each K\n",
    "results = []\n",
    "\n",
    "# Iterate over different K values\n",
    "for k in k_values:\n",
    "    # Initialize K-Fold Cross-Validation\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Initialize lists to store R² scores for this K\n",
    "    train_r2_scores = []\n",
    "    test_r2_scores = []\n",
    "    \n",
    "    # Define the AdaBoost Regressor\n",
    "    model = AdaBoostRegressor(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    for train_index, test_index in kf.split(DPP_DTT_X):\n",
    "        # Split data into training and test sets\n",
    "        X_train, X_test = DPP_DTT_X.iloc[train_index], DPP_DTT_X.iloc[test_index]\n",
    "        y_train, y_test = DPP_DTT_Y.iloc[train_index], DPP_DTT_Y.iloc[test_index]\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on training and test sets\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate R² scores\n",
    "        train_r2 = r2_score(y_train, y_train_pred)\n",
    "        test_r2 = r2_score(y_test, y_test_pred)\n",
    "        \n",
    "        # Append scores\n",
    "        train_r2_scores.append(train_r2)\n",
    "        test_r2_scores.append(test_r2)\n",
    "    \n",
    "    # Store average R² scores for this K\n",
    "    results.append({\n",
    "        'K': k,\n",
    "        'Avg Train R²': np.mean(train_r2_scores),\n",
    "        'Avg Test R²': np.mean(test_r2_scores)\n",
    "    })\n",
    "\n",
    "# Convert results to a DataFrame for better readability\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Print the results\n",
    "print(\"K-Fold Cross-Validation Results:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a969a9b-6483-4510-b78d-f2d70eeae542",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install bayesian-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3865fa3-435c-409f-9540-4a3839f7f5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "# Define the objective function for Bayesian Optimization\n",
    "def objective_function(**params):\n",
    "    # Convert parameters to float (BayesianOptimization passes them as numpy.float64)\n",
    "    params = {k: float(v) for k, v in params.items()}\n",
    "    \n",
    "    # Instantiate AdaBoost Regressor with given parameters\n",
    "    model = AdaBoostRegressor(\n",
    "        n_estimators=int(params['n_estimators']),\n",
    "        learning_rate=params['learning_rate']\n",
    "    )\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Return the R^2 score as the objective\n",
    "    return r2_score(y_test, y_pred)\n",
    "\n",
    "# Define the parameter space for Bayesian Optimization\n",
    "pbounds = {\n",
    "    'n_estimators': (10, 200),  # Number of estimators\n",
    "    'learning_rate': (0.01, 1.0)  # Learning rate\n",
    "}\n",
    "\n",
    "# Initialize Bayesian Optimizer\n",
    "optimizer = BayesianOptimization(\n",
    "    f=objective_function,\n",
    "    pbounds=pbounds,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Perform the optimization\n",
    "optimizer.maximize(\n",
    "    init_points=5,  # Number of initial random points\n",
    "    n_iter=20  # Number of iterations\n",
    ")\n",
    "\n",
    "# Output the best parameters and the corresponding R^2 score\n",
    "print(\"Best parameters:\", optimizer.max['params'])\n",
    "print(\"Best R^2 score:\", optimizer.max['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceeaccd-7052-4f97-b2a8-03f67968e63e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON Objects in PostgreSQL\n",
    "\n",
    "**Author**: Aaron Liu & Ron Volkovinsky\n",
    "\n",
    "**Date**: 5/10/2023\n",
    "\n",
    "**Objective**: Practice basic insert queries using SQL, and the corresponding programming to automate the process in psycopg2\n",
    "\n",
    "## Setup\n",
    "\n",
    "Some functions in python are already given in the cells below:\n",
    "\n",
    "**DOI JSON retrieval (doi2dict)**\n",
    "(Credit Ron Volkovinsky)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import bibtexparser\n",
    "import pprint\n",
    "\n",
    "def doi2dict(doi):\n",
    "    #create url\n",
    "    url = \"http://dx.doi.org/\" + doi\n",
    "    \n",
    "    #create dictionary of http bibtex headers that requests will retrieve from the url\n",
    "    headers = {\"accept\": \"application/x-bibtex\"}\n",
    "    \n",
    "    #reqeusts information specified by bibtex from url\n",
    "    r = requests.get(url, headers = headers).text    \n",
    "\n",
    "    #parse the returned bibtex text to a dictionary\n",
    "    #NOTE: USE bibtexparser.customization to split strings into list, etc. (https://bibtexparser.readthedocs.io/en/master/bibtexparser.html?highlight=bparser#module-bibtexparser.bparser)\n",
    "    bibdata = bibtexparser.bparser.BibTexParser().parse(r)\n",
    "    \n",
    "    #return dict of metadata\n",
    "    #return bibdata.entries[0]\n",
    "    if len(bibdata.entries) > 0:\n",
    "        return bibdata.entries[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "doi = '10.1021/acsami.1c20994'\n",
    "doi2 = '10.1021/.9b00476'\n",
    "\n",
    "doidict = doi2dict(doi2)\n",
    "print(doidict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Connection Details**\n",
    "\n",
    "Fill in your connection details here. Note that `127.0.0.1`, `localhost`, and your **local IP address** (found using the `ipconfig` command in your command line) are all synonymous with your local computer as a server. If you are connecting to an external server, you of course need to find the appropriate connection details of that server.\n",
    "\n",
    "I recommend creating your own database as a test environment for interacting with your database. You must do this either through psql or pgAdmin, externally from Python. Call the database whatever you want, like `pg_practice` or `ofetdb_testenv`, etc. Either way, the default username and password are what go into the connection details. The port by default for PostgreSQL is almost always `5432`, unless this was specified differently during your installation of PostgreSQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2 as pg\n",
    "import sys\n",
    "\n",
    "\n",
    "conn_kwargs = {\n",
    "    \"host\"      : \"localhost\",\n",
    "    \"database\"  : \"test_tutor\", ## FILL IN CONNECTION DETAILS HERE\n",
    "    \"user\"      : \"postgres\",\n",
    "    \"password\"  : \"password\",\n",
    "    \"port\"      : \"5432\",\n",
    "}\n",
    "\n",
    "def connect(**params_dict):\n",
    "    \"\"\" Connect to the PostgreSQL database server \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        # connect to the PostgreSQL server\n",
    "        print('Connecting to the PostgreSQL database...')\n",
    "        conn = pg.connect(**params_dict)\n",
    "    except (Exception, pg.DatabaseError) as error:\n",
    "        print(error)\n",
    "        sys.exit(1) \n",
    "    print(\"Connection successful\")\n",
    "    return conn\n",
    "\n",
    "conn = connect(**conn_kwargs)\n",
    "\n",
    "conn.close()\n",
    "print(\"Connection Closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postgres python\n",
    "import psycopg2 as pg\n",
    "import numpy as np\n",
    "from psycopg2.extensions import AsIs\n",
    "\n",
    "# import os\n",
    "# import functools\n",
    "# import sys\n",
    "\n",
    "# Adapters necessary for converting python data types to PostgreSQL compatible data types \n",
    "def addapt_numpy_float64(numpy_float64):\n",
    "    return AsIs(numpy_float64)\n",
    "\n",
    "def addapt_numpy_int64(numpy_int64):\n",
    "    return AsIs(numpy_int64)\n",
    "\n",
    "def nan_to_null(f,\n",
    "        _NULL=AsIs('NULL'),\n",
    "        _Float=pg.extensions.Float):\n",
    "    if not np.isnan(f):\n",
    "        return _Float(f)\n",
    "    return _NULL\n",
    "\n",
    "pg.extensions.register_adapter(np.float64, addapt_numpy_float64)\n",
    "pg.extensions.register_adapter(np.int64, addapt_numpy_int64)\n",
    "pg.extensions.register_adapter(float, nan_to_null)\n",
    "\n",
    "def pg_query(sql, tup):\n",
    "    \n",
    "    try:\n",
    "        # Database connection\n",
    "        conn = pg.connect(**conn_kwargs)\n",
    "        cur = conn.cursor()\n",
    "        \n",
    "        # Pass SQL query, using string and placeholders\n",
    "        cur.execute(sql, tup)\n",
    "        \n",
    "#         # Fetch result\n",
    "#         fetched = cur.fetchone()[0]\n",
    "        \n",
    "        # Commit result\n",
    "        conn.commit()\n",
    "        print(\"Operation Successful\")\n",
    "\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "        \n",
    "    except (Exception, pg.DatabaseError) as error:\n",
    "        # If database connection unsuccessful, then close connection \n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table that holds journal article information\n",
    "conn = connect(**conn_kwargs)\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "sql = '''\n",
    "\n",
    "    DROP TABLE IF EXISTS EXPERIMENT_INFO;\n",
    "\n",
    "    CREATE TABLE EXPERIMENT_INFO (\n",
    "        exp_id              SERIAL          PRIMARY KEY,\n",
    "        citation_type       VARCHAR(20),\n",
    "        meta                JSONB,\n",
    "        UNIQUE(citation_type, meta)\n",
    "    );\n",
    "'''\n",
    "\n",
    "cur.execute(sql)\n",
    "conn.commit()\n",
    "\n",
    "print(\"Operation successful\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doidict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg2.extras import Json\n",
    "\n",
    "doi = '10.1021/acsami.1c20994'\n",
    "doi2 = '10.1021/acscentsci.9b00476'\n",
    "\n",
    "doidict = doi2dict(doi)\n",
    "\n",
    "a = Json(doidict)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "kwargs = {\n",
    "    'database': 'test_tutor',\n",
    "    'user': 'postgres',\n",
    "    'password': 'password',\n",
    "    'host': '127.0.0.1',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "# %% Create Tables for EXPERIMENT_INFO\n",
    "\n",
    "conn = psycopg2.connect(**kwargs)\n",
    "\n",
    "print(\"Connection Successful\")\n",
    "\n",
    "cur = conn.cursor()\n",
    "cur.execute(\n",
    "    '''\n",
    "    CREATE TABLE IF NOT EXISTS EXPERIMENT_INFO (\n",
    "        exp_id              SERIAL          PRIMARY KEY,\n",
    "        citation_type       VARCHAR(20),\n",
    "        meta                JSONB,\n",
    "        UNIQUE(citation_type, meta)\n",
    "    );\n",
    "    '''\n",
    ")\n",
    "\n",
    "print(\"Table(s) created successfully\")\n",
    "conn.commit()\n",
    "\n",
    "print(\"Operation successful\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Json(doidict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"INSERT INTO experiment_info(%s) VALUES %s\"\n",
    "\n",
    "columns = ['citation_type', 'meta']\n",
    "values = ['literature', Json(doidict)]\n",
    "\n",
    "tup = (AsIs(','.join(columns)), tuple(values))\n",
    "\n",
    "conn = psycopg2.connect(**kwargs)\n",
    "\n",
    "print(\"Connection Successful\")\n",
    "\n",
    "cur = conn.cursor()\n",
    "cur.execute(sql, tup)\n",
    "\n",
    "print(\"Table(s) created successfully\")\n",
    "conn.commit()\n",
    "\n",
    "print(\"Operation successful\")\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Populate a journal article DOI table\n",
    "\n",
    "1. Create a table called Articles. We want the table to contain columns that store a unique id for each row, the year it was published, and a metadata field with variable information mined using bibtexparser\n",
    "2. Populate the table with all the information using the Excel file \"articles.xlsx\" provided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_kwargs= {\n",
    "    'database': 'test_tutor',\n",
    "    'user': 'postgres',\n",
    "    'password': 'password',\n",
    "    'host': 'localhost',\n",
    "    'port': '5432'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pg.connect returns a connection instance, based on the login parameters\n",
    "conn = pg.connect(**conn_kwargs)\n",
    "print(\"Connection Successful\")\n",
    "\n",
    "# A cursor object is used to query the database from Python\n",
    "cur = conn.cursor()\n",
    "\n",
    "# The execute command takes a query as an argument. This query is creating a SOLVENT table. \n",
    "# Note, inside the triple quotes is exactly what you would type into an SQL interface\n",
    "sql = '''\n",
    "    \n",
    "    DROP TABLE IF EXISTS ARTICLES;\n",
    "    \n",
    "    CREATE TABLE ARTICLES (\n",
    "        id            BIGSERIAL         PRIMARY KEY,\n",
    "        year          INT ,\n",
    "        meta          JSONB,\n",
    "        UNIQUE(meta)\n",
    "    ); \n",
    "    '''\n",
    "\n",
    "cur.execute(sql)\n",
    "\n",
    "\n",
    "print(\"Table(s) created successfully\")\n",
    "conn.commit()\n",
    "\n",
    "print(\"Operation successful\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##from doi into json file type\n",
    "df = pd.read_excel('articles.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert Data Into Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"year\", \"meta\"]\n",
    "\n",
    "sql = '''\n",
    "INSERT INTO ARTICLES (%s) VALUES %s\n",
    "ON CONFLICT (meta) \n",
    "DO UPDATE SET meta = excluded.meta;\n",
    "'''\n",
    "\n",
    "for index , row in df.iterrows():\n",
    "    article= row['doi']\n",
    "    doi = doi2dict(article)\n",
    "    if doi is not None:\n",
    "        data = Json(doi)\n",
    "        values= [doi['year'],data]\n",
    "        tup = (AsIs(','.join(columns)),tuple(values))\n",
    "        pg_query(sql,tup)\n",
    "    else:\n",
    "        print(f'No metadata found for doi={article}')\n",
    "\n",
    "    \n",
    "#     values = tuple(row)\n",
    "#     tup = (AsIs(','.join(columns)),values)\n",
    "#     pg_insert(sql,tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I left off talking about inserting new tuples that already exist... and violating key constraints. What about sequencing?\n",
    "## Let's insert like 5 doi's, see what happens"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

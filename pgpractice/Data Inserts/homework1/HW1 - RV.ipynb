{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Insert Exercises\n",
    "\n",
    "In this set of exercises, you will practice a series of transactions using a dataset of solution-based experiments. You will find the data you need under `data\\solution_experiments.xlsx`.\n",
    "\n",
    "The first two sheets `solvent` and `polymer` contain a list of chemicals that are contained in a hypothetical laboratory storage. The third sheet, `solution`, contains a list of solutions that a hypothetical student named Jason, has made in the last several months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\Anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import bibtexparser #API for requesting DOI information\n",
    "import pprint as pp #The function pp.pprint helps with better visualizing nested key-value information\n",
    "import psycopg2 as pg # Postgres python\n",
    "import numpy as np\n",
    "import sys\n",
    "from psycopg2.extensions import AsIs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions\n",
    "\n",
    "# Adapters necessary for converting python data types to PostgreSQL compatible data types \n",
    "def addapt_numpy_float64(numpy_float64):\n",
    "    return AsIs(numpy_float64)\n",
    "\n",
    "def addapt_numpy_int64(numpy_int64):\n",
    "    return AsIs(numpy_int64)\n",
    "\n",
    "def nan_to_null(f,\n",
    "        _NULL=AsIs('NULL'),\n",
    "        _Float=pg.extensions.Float):\n",
    "    if not np.isnan(f):\n",
    "        return _Float(f)\n",
    "    return _NULL\n",
    "\n",
    "pg.extensions.register_adapter(np.float64, addapt_numpy_float64)\n",
    "pg.extensions.register_adapter(np.int64, addapt_numpy_int64)\n",
    "pg.extensions.register_adapter(float, nan_to_null)\n",
    "\n",
    "def connect(params_dict):\n",
    "    \"\"\" Connect to the PostgreSQL database server \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        # connect to the PostgreSQL server\n",
    "        print('Connecting to the PostgreSQL database...')\n",
    "        conn = pg.connect(**params_dict)\n",
    "    except (Exception, pg.DatabaseError) as error:\n",
    "        print(error)\n",
    "        sys.exit(1) \n",
    "    print(\"Connection successful\")\n",
    "    return conn\n",
    "\n",
    "def pg_query(sql, tup):\n",
    "    \n",
    "    try:\n",
    "        # Database connection\n",
    "        conn = pg.connect(**conn_kwargs)\n",
    "        cur = conn.cursor()\n",
    "        \n",
    "        # Pass SQL query, using string and placeholders\n",
    "        cur.execute(sql, tup)\n",
    "        \n",
    "#         # Fetch result\n",
    "#         fetched = cur.fetchone()[0]\n",
    "        \n",
    "        # Commit result\n",
    "        conn.commit()\n",
    "        print(\"Operation Successful\")\n",
    "\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "        \n",
    "    except (Exception, pg.DatabaseError) as error:\n",
    "        # If database connection unsuccessful, then close connection \n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "Connection successful\n",
      "Connection Closed\n"
     ]
    }
   ],
   "source": [
    "conn_kwargs = {\n",
    "    \"host\"      : \"localhost\",\n",
    "    \"database\"  : \"test\", ## FILL IN CONNECTION DETAILS HERE\n",
    "    \"user\"      : \"postgres\",\n",
    "    \"password\"  : \"Rahul2411!\",\n",
    "    \"port\"      : \"5432\",\n",
    "}\n",
    "\n",
    "def connect(**params_dict):\n",
    "    \"\"\" Connect to the PostgreSQL database server \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        # connect to the PostgreSQL server\n",
    "        print('Connecting to the PostgreSQL database...')\n",
    "        conn = pg.connect(**params_dict)\n",
    "    except (Exception, pg.DatabaseError) as error:\n",
    "        print(error)\n",
    "        sys.exit(1) \n",
    "    print(\"Connection successful\")\n",
    "    return conn\n",
    "\n",
    "conn = connect(**conn_kwargs)\n",
    "\n",
    "conn.close()\n",
    "print(\"Connection Closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create Polymer and Solvent Tables\n",
    "\n",
    "First, please create from scratch two tables which contain the chemical inventory of the laboratory (Solvent and Polymer). \n",
    "\n",
    "* Solvent contains three attributes: a unique identifier given from its PubChem CID, its IUPAC name, and boiling points\n",
    "* Polymer should contain a unique identifier of your choice (e.g., \"polymer_id\"), two columns for its common name and its full name, and three fields for molecular weight information (Mn, Mw, dispersity)\n",
    "\n",
    "The primary key for `solvent` should be the PubChem CID, and the primary key for `polymer` should be a one that you generate. You may use the `SERIAL` data type to facilitate automatic key generation for new rows. Make sure you add `UNIQUE` constraints that properly account for the real-world scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "Connection successful\n",
      "Operation successful\n"
     ]
    }
   ],
   "source": [
    "conn = connect(**conn_kwargs)\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "sql = '''\n",
    "\n",
    "    DROP TABLE IF EXISTS SOLVENT;\n",
    "    \n",
    "    CREATE TABLE SOLVENT (\n",
    "        pubchem_cid         INT             PRIMARY KEY,             \n",
    "        iupac_name          VARCHAR(50),\n",
    "        boiling_point       FLOAT,\n",
    "        UNIQUE(iupac_name)\n",
    "    );\n",
    "    \n",
    "    \n",
    "    DROP TABLE IF EXISTS POLYMER;\n",
    "    \n",
    "    CREATE TABLE POLYMER (\n",
    "        polymer_id          SERIAL          PRIMARY KEY,\n",
    "        common_name         VARCHAR(500),\n",
    "        iupac_name          VARCHAR(500),\n",
    "        Mn       FLOAT,\n",
    "        Mw       FLOAT,\n",
    "        dispersity        FLOAT,\n",
    "        UNIQUE(common_name,iupac_name,Mn,Mw,dispersity)\n",
    "    );\n",
    "'''\n",
    "\n",
    "cur.execute(sql)\n",
    "conn.commit()\n",
    "\n",
    "print(\"Operation successful\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create a Record of Solutions\n",
    "\n",
    "Next, we must create a table to store new experimental records of solutions that are made from the laboratory reagents available in inventory. Recently, Jason has only been interested in testing the solubility of single polymers in solution. In his digital lab notebook, he has written down the date he made the solution, the concentration of the solution, and what polymer and solvent he used. Usually, Jason was a good student and wrote down the batch information (molecular weights, dispersity) of the polymer, but sometimes he was an idiot and forgot. Regardless, we should record all of the data points. \n",
    "\n",
    "1. Create an entity-relationship diagram that shows the connections between polymer, solvent, and solution.\n",
    "\n",
    "2. Create a table `solution` that accurately models the conceptual schema you generated in the ERD.\n",
    "\n",
    "`solution` should contain five attributes: This includes:\n",
    "\n",
    "* A primary key (a solution identifier)\n",
    "* Two foreign keys (referencing the polymer and solvent table)\n",
    "* Two fields that describe the solution concentration and the date the solution was created\n",
    "\n",
    "**Warning**: Do not use the given dataset columns to decide how you actually name your columns. Name your attributes in a way that is friendly to programming. For this example, feel free to ignore units. We will deal with that another day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "Connection successful\n",
      "Operation successful\n"
     ]
    }
   ],
   "source": [
    "sql = '''\n",
    "\n",
    "DROP TABLE IF EXISTS SOLUTION;\n",
    "\n",
    "CREATE TABLE SOLUTION(\n",
    "    solution_id    SERIAL   PRIMARY KEY,\n",
    "    solution_concentration   FLOAT,\n",
    "    solvent_id     INT,\n",
    "    polymer_id     INT,\n",
    "    date_created   DATE,\n",
    "    \n",
    "    FOREIGN KEY(polymer_id) REFERENCES POLYMER(polymer_id)\n",
    "            ON DELETE SET NULL ON UPDATE CASCADE,\n",
    "    FOREIGN KEY(solvent_id) REFERENCES SOLVENT(pubchem_cid)\n",
    "            ON DELETE SET NULL ON UPDATE CASCADE\n",
    ")\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "conn = connect(**conn_kwargs)\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(sql)\n",
    "conn.commit()\n",
    "\n",
    "print(\"Operation successful\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Populate the Lab Inventory\n",
    "\n",
    "In this example, you can pretend that you exported Sheets 1 and 2 of solution_experiments.xlsx from an online inventory manager, and you want to input it into your own database. Upload the inventory in sheets 1 and 2 to `polymer` and `solvent`. \n",
    "\n",
    "As a note: sometimes, the online manager accidentally duplicates records, so you want to ensure that no duplicates exist in your local copy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pd.ExcelFile('data/solution_experiments.xlsx')\n",
    "df_solvent = db.parse('solvent')\n",
    "df_polymer = db.parse('polymer')\n",
    "df_solution = db.parse('solution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n"
     ]
    }
   ],
   "source": [
    "#Inserting into solvent table\n",
    "\n",
    "sql = '''\n",
    "INSERT INTO SOLVENT (%s) VALUES %s\n",
    "'''\n",
    "columns = list(df_solvent.columns)\n",
    "\n",
    "for row in df_solvent.itertuples(index=False):\n",
    "    values = tuple(row)\n",
    "    tup = (AsIs(','.join(columns)),values)\n",
    "    pg_query(sql,tup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n"
     ]
    }
   ],
   "source": [
    "#Inserting into polymer table\n",
    "\n",
    "sql = '''\n",
    "INSERT INTO POLYMER (%s) VALUES %s\n",
    "ON CONFLICT(common_name,iupac_name,Mn,Mw,dispersity) DO NOTHING\n",
    "'''\n",
    "columns = list(df_polymer.columns)\n",
    "\n",
    "for row in df_polymer.itertuples(index=False):\n",
    "    values = (tuple(row))\n",
    "    tup = (AsIs(','.join(columns)),values)\n",
    "    pg_query(sql,tup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Update Jason's Experimental Records\n",
    "\n",
    "Using the \"Solution\" sheet in the Excel file, figure out a way to import Jason's historical record of solution-based experiments into the `solution` table you made in PostgreSQL. Make sure you properly tailor Jason's dataset to the schema that you created in **Part 2**. \n",
    "\n",
    "Hints:\n",
    "* You may have to do some python pre-processing to generate the tuple you want. Don't be afraid to make a few helper functions that do that.\n",
    "* Jason is not going to write PubChem IDs in his laboratory notebook, because he's not insane. You will have to find a way to look up the PubChem ID that is associated with a given solvent name. You might be able to do this in your SQL query. More information: https://dba.stackexchange.com/questions/46410/how-do-i-insert-a-row-which-contains-a-foreign-key\n",
    "* Similarly, you're not putting all of the polymer information into your solution table, because that would be redundant. Instead, you need to look up which polymer he used from the known inventory, and assign the polymer_id that way\n",
    "\n",
    "If the link above does not help, try to find your own resources! Programming isn't always easy, but this is a standard transaction that many other people have probably tried to do. Learn how to learn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "Connection successful\n"
     ]
    }
   ],
   "source": [
    "#Inserting into solution table\n",
    "\n",
    "# Establish a connection to the PostgreSQL database\n",
    "conn = connect(**conn_kwargs)\n",
    "\n",
    "# Create a cursor object to execute SQL queries\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Loop through each row of the DataFrame and insert the data into the solution table\n",
    "for _, row in df_solution.iterrows():\n",
    "    \n",
    "    #print(row)\n",
    "    \n",
    "    # Retrieve the solvent_id based on the solvent name from the solvent table\n",
    "    cur.execute(\"SELECT pubchem_cid FROM solvent WHERE iupac_name = %s\", (row['Solvent Name'],))\n",
    "    solvent_id = cur.fetchone()[0]  # Assuming there's only one matching solvent\n",
    "    \n",
    "    # Check if at least one of the required columns has a non-null value\n",
    "    if pd.notnull(row['Mw (kg/mol)']) or pd.notnull(row['Mn (kg/mol)']) or pd.notnull(row['PDI']):\n",
    "        # Retrieve the polymer_id based on the polymer, molecular weight, molecular number, and dispersity from the polymer table\n",
    "        if pd.notnull(row['Mw (kg/mol)']) and pd.notnull(row['Mn (kg/mol)']) and pd.notnull(row['PDI']):\n",
    "            # If all required columns have non-null values, use the exact match query\n",
    "            cur.execute(\"SELECT polymer_id FROM polymer WHERE common_name = %s AND mw = %s AND mn = %s AND dispersity = %s\",\n",
    "                        (row['Polymer Used'], row['Mw (kg/mol)'], row['Mn (kg/mol)'], row['PDI']))\n",
    "        else:\n",
    "            # If any of the required columns have null values, use a query with null handling\n",
    "            cur.execute(\"SELECT polymer_id FROM polymer WHERE common_name = %s AND (mw = %s OR mw IS NULL) AND (mn = %s OR mn IS NULL) AND (dispersity = %s OR dispersity IS NULL)\",\n",
    "                        (row['Polymer Used'], row['Mw (kg/mol)'], row['Mn (kg/mol)'], row['PDI']))\n",
    "            \n",
    "        polymer_id = cur.fetchone()[0]  # Assuming there's only one matching polymer\n",
    "        \n",
    "        # Insert the data into the solution table\n",
    "        cur.execute(\"INSERT INTO solution (solvent_id, polymer_id, solution_concentration, date_created) VALUES (%s, %s, %s, %s)\",\n",
    "                    (solvent_id, polymer_id, row['Solution Concentration (mg/mL)'], row['Date Created']))\n",
    "\n",
    "# Commit the changes to the database\n",
    "conn.commit()\n",
    "\n",
    "# Close the cursor and the connection\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Upload New Experiments\n",
    "\n",
    "Two weeks later, Jason compiles another dataset with a new set of solutions. After speaking with his advisor, he has actually decided to test a few new solvents to try out. You can find these new solutions within `data/new_experiments.xlsx`\n",
    "\n",
    "Add these new experiments to the relational database that you have generated. \n",
    "\n",
    "* Note that the solution table contains reagents that have not previously been added to the inventory. What happens when you try to import the data with the queries you generated above? What type of constraint is this called?\n",
    "* Can you figure out how to structure queries or a workflow that will account for this situation? For example: Try inserting the record. If the solvent does not exist, get the PubChem CID using an API, add it to the `solvent` table, and retry the add. Normally, I would also ask you do this with polymers; i.e., if the polymer does not exist, similarly add new information to the `polymer` table, then retry the add -- but for now let's try the exercise with solvent only. You can assume he only experimented on existing polymers.\n",
    "\n",
    "The below code block contains a simple *Chemical Name to PubChem CID* function. You may use it to facilitate the programming process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#workflow :\n",
    "#1.Go through the solvents in the new_experiment excel sheet and generate the PubChem_CID and boiling point using some API\n",
    "  #** (NOTE the boiling point is hard to obtain from most APIs)\n",
    "#2.Check with solvent table and add records that are not present in solvent table\n",
    "#3.Now add new records to the solution table if they are not duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_New = pd.ExcelFile('data/new_experiments.xlsx')\n",
    "df_New = db_New.parse('new_experiments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6212]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pubchempy as pcpy #You may have to pip or conda install pubchempy API. \n",
    "\n",
    "#Read more here: https://pubchempy.readthedocs.io/en/latest/\n",
    "\n",
    "def name2cid(chemName):\n",
    "    cid = pcpy.get_cids(chemName)\n",
    "    bp  = pcpy.get_\n",
    "    #if chemname isn't valid, cid will return an empty array. if so, this if statement will return an error message.\n",
    "    if not cid:\n",
    "        return 'Please enter a valid name.'\n",
    "    else:\n",
    "        return cid\n",
    "\n",
    "name2cid('chloroform')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus\n",
    "\n",
    "You may have seen that a lot of these queries can be challenging to program using just psycopg2. Many online articles and tutorials recommend the use of SQLAlchemy to facilitate the generation of queries, and many Python users prefer it because it \"requires little knowledge of SQL\". Your bonus assignment is to test this theory by exploring SQLAlchemy on your own. For example, can you perform all of the questions in this homework with the help of an SQLAlchemy connection to your database? You are a superstar if you do this entire exercise with SQLAlchemy, and you'll be on your way to helping develop OFETdb. But for starters, try the first few problems.\n",
    "\n",
    "Here is a tutorial I found, but feel free to find others on YouTube or Google, or just ask ChatGPT.\n",
    "https://www.learndatasci.com/tutorials/using-databases-python-postgres-sqlalchemy-and-alembic/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

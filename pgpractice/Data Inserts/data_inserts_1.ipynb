{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PostgreSQL and Python 1\n",
    "\n",
    "**Author**: Aaron Liu\n",
    "\n",
    "**Date**: 5/9/2023\n",
    "\n",
    "**Objective**: Practice basic insert queries using SQL, and the corresponding programming to automate the process in psycopg2\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Premade psycopg2 functions**\n",
    "\n",
    "When using pandas or numpy to work with data types, adapters are required to switch between Python and PostgreSQL data types. A connection function is also provided, for your convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2 as pg # Postgres python\n",
    "import numpy as np\n",
    "import sys\n",
    "from psycopg2.extensions import AsIs\n",
    "\n",
    "# # Adapters necessary for converting python data types to PostgreSQL compatible data types \n",
    "# def addapt_numpy_float64(numpy_float64):\n",
    "#     return AsIs(numpy_float64)\n",
    "\n",
    "# def addapt_numpy_int64(numpy_int64):\n",
    "#     return AsIs(numpy_int64)\n",
    "\n",
    "# def nan_to_null(f,\n",
    "#         _NULL=AsIs('NULL'),\n",
    "#         _Float=pg.extensions.Float):\n",
    "#     if not np.isnan(f):\n",
    "#         return _Float(f)\n",
    "#     return _NULL\n",
    "\n",
    "# pg.extensions.register_adapter(np.float64, addapt_numpy_float64)\n",
    "# pg.extensions.register_adapter(np.int64, addapt_numpy_int64)\n",
    "# pg.extensions.register_adapter(float, nan_to_null)\n",
    "\n",
    "def connect(params_dict):\n",
    "    \"\"\" Connect to the PostgreSQL database server \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        # connect to the PostgreSQL server\n",
    "        print('Connecting to the PostgreSQL database...')\n",
    "        conn = pg.connect(**params_dict)\n",
    "    except (Exception, pg.DatabaseError) as error:\n",
    "        print(error)\n",
    "        sys.exit(1) \n",
    "    print(\"Connection successful\")\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Connection Details**\n",
    "\n",
    "Fill in your connection details here. Note that `127.0.0.1`, `localhost`, and your **local IP address** (found using the `ipconfig` command in your command line) are all synonymous with your local computer as a server. If you are connecting to an external server, you of course need to find the appropriate connection details of that server.\n",
    "\n",
    "I recommend creating your own database as a test environment for interacting with your database. You must do this either through psql or pgAdmin, externally from Python. Call the database whatever you want, like `pg_practice` or `ofetdb_testenv`, etc. Either way, the default username and password are what go into the connection details. The port by default for PostgreSQL is almost always `5432`, unless this was specified differently during your installation of PostgreSQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection Successful\n",
      "Connection Closed\n"
     ]
    }
   ],
   "source": [
    "conn_kwargs = {\n",
    "    \"host\"      : \"localhost\",\n",
    "    \"database\"  : \"test\", ## FILL IN CONNECTION DETAILS HERE\n",
    "    \"user\"      : \"postgres\",\n",
    "    \"password\"  : \"password\",\n",
    "    \"port\"      : \"5432\",\n",
    "}\n",
    "\n",
    "conn = pg.connect(**conn_kwargs)\n",
    "print(\"Connection Successful\")\n",
    "\n",
    "conn.close()\n",
    "print(\"Connection Closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ALWAYS** ensure that you close a connection after any given operation. Any idle connections can otherwise prevent database managers from updating the database on the backend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating Tables**\n",
    "\n",
    "For this session, we will work with two different tables of information. The first is a list of chemicals, and the second is a list of journal articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection Successful\n",
      "Table(s) created successfully\n",
      "Operation successful\n"
     ]
    }
   ],
   "source": [
    "# pg.connect returns a connection instance, based on the login parameters\n",
    "conn = pg.connect(**conn_kwargs)\n",
    "print(\"Connection Successful\")\n",
    "\n",
    "# A cursor object is used to query the database from Python\n",
    "cur = conn.cursor()\n",
    "\n",
    "# The execute command takes a query as an argument. This query is creating a SOLVENT table. \n",
    "# Note, inside the triple quotes is exactly what you would type into an SQL interface\n",
    "sql = '''\n",
    "    \n",
    "    DROP TABLE IF EXISTS SOLVENT;\n",
    "    \n",
    "    CREATE TABLE SOLVENT (\n",
    "        pubchem_cid   INT         PRIMARY KEY,\n",
    "        iupac_name    VARCHAR(50) UNIQUE,\n",
    "        boiling_point FLOAT\n",
    "    ); \n",
    "    '''\n",
    "\n",
    "cur.execute(sql)\n",
    "\n",
    "\n",
    "print(\"Table(s) created successfully\")\n",
    "conn.commit()\n",
    "\n",
    "print(\"Operation successful\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Inserts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by filling up the `SOLVENT` table with some chemicals. From SQL, the syntax would be as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection Successful\n",
      "Table(s) created successfully\n",
      "Operation successful\n",
      "Connection closed\n"
     ]
    }
   ],
   "source": [
    "# Again, we can store the query as a string and execute it with psycopg2\n",
    "sql = '''\n",
    "INSERT INTO SOLVENT(pubchem_cid, iupac_name, boiling_point) \n",
    "VALUES (13, '1,2,4-trichlorobenzene', 214.4)\n",
    "'''\n",
    "\n",
    "# pg.connect returns a connection instance, based on the login parameters\n",
    "conn = pg.connect(**conn_kwargs)\n",
    "print(\"Connection Successful\")\n",
    "\n",
    "# A cursor object is used to query the database from Python\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(sql)\n",
    "\n",
    "print(\"Table(s) created successfully\")\n",
    "conn.commit()\n",
    "\n",
    "print(\"Operation successful\")\n",
    "conn.close()\n",
    "print(\"Connection closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will delete rows from the SOLVENT table. We will cover duplicate keys later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_solvent_rows():\n",
    "    \n",
    "    delete_query = \"DELETE FROM SOLVENT *\"\n",
    "\n",
    "    # pg.connect returns a connection instance, based on the login parameters\n",
    "    conn = connect(conn_kwargs)\n",
    "\n",
    "    # A cursor object is used to query the database from Python\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    cur.execute(delete_query)\n",
    "\n",
    "    print(\"All rows deleted\")\n",
    "    conn.commit()\n",
    "\n",
    "    print(\"Operation successful\")\n",
    "    conn.close()\n",
    "    print(\"Connection closed\")\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "Connection successful\n",
      "All rows deleted\n",
      "Operation successful\n",
      "Connection closed\n"
     ]
    }
   ],
   "source": [
    "delete_solvent_rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**String Formatting**\n",
    "\n",
    "The above code functions well enough, but it's really not scalable. What if you want to add 10 different solvents at a time? An advantage of psycopg2 is that it makes room for automating most queries. To illustrate this, let's look at something that has nothing to do with psycopg2, but just Python syntax in general: string formatting. \n",
    "\n",
    "See below for two possible ways of printing a string. Read more at: https://www.geeksforgeeks.org/what-does-s-mean-in-a-python-format-string/#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is Theodore\n"
     ]
    }
   ],
   "source": [
    "print(\"My name is Theodore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is Theodore\n"
     ]
    }
   ],
   "source": [
    "name = \"Theodore\"\n",
    "print(\"My name is %s\" % name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, but what is the utility of this? A couple things: most importantly, you can use the `%s` to cast anything as a string, even if it's a different data type. Secondly, it allows you to automate things through loops. The `%s` is kind of like a placeholder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The boiling point of 1,2,4-trichlorobenzene is 214.4°C\n",
      "The boiling point of benzene is 80.1°C\n",
      "The boiling point of toluene is 110.6°C\n",
      "The boiling point of chloroform is 61.2°C\n",
      "The boiling point of 1,1,2,2-tetrachloroethane is 146.6°C\n",
      "The boiling point of 1-chloronaphthalene is 305.2°C\n"
     ]
    }
   ],
   "source": [
    "solvents = [\"1,2,4-trichlorobenzene\", \"benzene\", \"toluene\", \"chloroform\", \"1,1,2,2-tetrachloroethane\", \"1-chloronaphthalene\"]\n",
    "boiling_points = [214.4, 80.1, 110.6, 61.2, 146.6, 305.2]\n",
    "\n",
    "my_str = \"The boiling point of %s is %s°C\"\n",
    "\n",
    "for solvent, bp in zip(solvents, boiling_points):\n",
    "    print(my_str % (solvent, bp))\n",
    "\n",
    "\n",
    "# # A string that will be repeated\n",
    "# my_str = \"The boiling point of %s is %s°C\"\n",
    "\n",
    "# # Print out a statement for all matching boiling points\n",
    "# for solvent, bp in zip(solvents, boiling_points):\n",
    "#     print(my_str % (solvent, bp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see how psycopg2 helps to apply the simplest formatting case to an insert. Note the INSERT statement that we use before presents the columns and values as a *tuple* (see: https://www.geeksforgeeks.org/tuples-in-python/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "Connection successful\n",
      "All rows deleted\n",
      "Operation successful\n",
      "Connection closed\n"
     ]
    }
   ],
   "source": [
    "delete_solvent_rows() #if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection Successful\n",
      "Record inserted successfully\n",
      "Operation successful\n",
      "Connection closed\n"
     ]
    }
   ],
   "source": [
    "# Again, we can store the query as a string and execute it with psycopg2\n",
    "sql = '''\n",
    "INSERT INTO SOLVENT (%s) VALUES %s\n",
    "'''\n",
    "\n",
    "columns = [\"pubchem_cid\", \"iupac_name\", \"boiling_point\"]\n",
    "values = (13, '1,2,4-trichlorobenzene', 214.4)\n",
    "\n",
    "tup = (AsIs(','.join(columns)), values)\n",
    "\n",
    "# pg.connect returns a connection instance, based on the login parameters\n",
    "conn = pg.connect(**conn_kwargs)\n",
    "print(\"Connection Successful\")\n",
    "\n",
    "# A cursor object is used to query the database from Python\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(sql, tup)\n",
    "\n",
    "print(\"Record inserted successfully\")\n",
    "conn.commit()\n",
    "\n",
    "print(\"Operation successful\")\n",
    "conn.close()\n",
    "print(\"Connection closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pg_insert(sql, tup):\n",
    "    \n",
    "    try:\n",
    "        # Database connection\n",
    "        conn = pg.connect(**conn_kwargs)\n",
    "        cur = conn.cursor()\n",
    "        \n",
    "        # Pass SQL query, using string and placeholders\n",
    "        cur.execute(sql, tup)\n",
    "        \n",
    "#         # Fetch result\n",
    "#         fetched = cur.fetchone()[0]\n",
    "        \n",
    "        # Commit result\n",
    "        conn.commit()\n",
    "        print(\"Operation Successful\")\n",
    "\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "        \n",
    "    except (Exception, pg.DatabaseError) as error:\n",
    "        # If database connection unsuccessful, then close connection \n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "    \n",
    "    return \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Insert from Excel\n",
    "\n",
    "The Microsoft Excel file `solvents.xlsx` contains simple data that obeys the same schema as the SOLVENT table. Write code to automate the population of the SOLVENT table using psycopg2, tuple logic, and other python syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: duplicate key value violates unique constraint \"solvent_pkey\"\n",
      "DETAIL:  Key (pubchem_cid)=(13) already exists.\n",
      "\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# import pprint as pp\n",
    "\n",
    "df = pd.read_excel('solvents.xlsx')\n",
    "\n",
    "sql = '''\n",
    "INSERT INTO SOLVENT (%s) VALUES %s\n",
    "'''\n",
    "\n",
    "cols = AsIs(','.join(df.columns))\n",
    "\n",
    "for row in df.itertuples(index=False, name=None): # note: iterating through the generator df.iterrows() returns rows as tuples\n",
    "    tup = (cols, row)\n",
    "    pg_insert(sql, tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "Connection successful\n",
      "All rows deleted\n",
      "Operation successful\n",
      "Connection closed\n"
     ]
    }
   ],
   "source": [
    "delete_solvent_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n"
     ]
    }
   ],
   "source": [
    "sql = '''\n",
    "INSERT INTO SOLVENT (%s) \n",
    "VALUES %s\n",
    "ON CONFLICT(pubchem_cid) DO UPDATE\n",
    "    SET iupac_name = excluded.iupac_name,\n",
    "        boiling_point = excluded.boiling_point;\n",
    "'''\n",
    "\n",
    "cols = AsIs(','.join(df.columns))\n",
    "\n",
    "for row in df.itertuples(index=False, name=None): # note: iterating through the generator df.iterrows() returns rows as tuples\n",
    "    tup = (cols, row)\n",
    "    pg_insert(sql, tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13229, 'cyclohexylbenzene', 257.0\n"
     ]
    }
   ],
   "source": [
    "print(AsIs(str(row)[1:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nINSERT INTO SOLVENT (pubchem_cid,iupac_name,boiling_point) \\nVALUES (13229, 'cyclohexylbenzene', 257.0)\\nON CONFLICT(pubchem_cid) \\nDO UPDATE SET (pubchem_cid,iupac_name,boiling_point) = \\n    (SELECT None)\\n    WHERE SOLVENT.constraint_columns = excluded.constraint_columns;\\n\\n\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql % tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n",
      "Operation Successful\n"
     ]
    }
   ],
   "source": [
    "sql = '''\n",
    "INSERT INTO SOLVENT (%s) \n",
    "VALUES %s\n",
    "ON CONFLICT(pubchem_cid) \n",
    "DO UPDATE SET (%s) = \n",
    "    (SELECT %s)\n",
    "    WHERE SOLVENT.pubchem_cid = excluded.pubchem_cid;\n",
    "\n",
    "'''\n",
    "\n",
    "cols = AsIs(','.join(df.columns))\n",
    "\n",
    "for row in df.itertuples(index=False, name=None): # note: iterating through the generator df.iterrows() returns rows as tuples\n",
    "    a = AsIs(str(row)[1:-1])\n",
    "    tup = (cols, row, cols, a)\n",
    "    pg_insert(sql, tup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aaron's question: Is there an easier way?\n",
    "\n",
    "https://towardsdatascience.com/the-easiest-way-to-upsert-with-sqlalchemy-9dae87a75c35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import bibtexparser #API for requesting DOI information\n",
    "import pprint as pp #The function pp.pprint helps with better visualizing nested key-value information\n",
    "\n",
    "# Given a valid doi string, return a dictionary of digital object information. Credit: Ron Volkovinsky\n",
    "def doi2dict(doi):\n",
    "    #create url\n",
    "    url = \"http://dx.doi.org/\" + doi\n",
    "    \n",
    "    #create dictionary of http bibtex headers that requests will retrieve from the url\n",
    "    headers = {\"accept\": \"application/x-bibtex\"}\n",
    "    \n",
    "    #reqeusts information specified by bibtex from url\n",
    "    r = requests.get(url, headers = headers).text    \n",
    "\n",
    "    #parse the returned bibtex text to a dictionary\n",
    "    #NOTE: USE bibtexparser.customization to split strings into list, etc. (https://bibtexparser.readthedocs.io/en/master/bibtexparser.html?highlight=bparser#module-bibtexparser.bparser)\n",
    "    bibdata = bibtexparser.bparser.BibTexParser().parse(r)\n",
    "    \n",
    "    #return dict of metadata\n",
    "    return bibdata.entries[0]\n",
    "\n",
    "doi = '10.1021/acsami.1c20994'\n",
    "\n",
    "doidict = doi2dict(doi)\n",
    "pp.pprint(doidict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2.extras import Json \n",
    "\n",
    "\n",
    "kwargs = {\n",
    "    'database': 'test',\n",
    "    'user': 'postgres',\n",
    "    'password': 'password',\n",
    "    'host': '127.0.0.1',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "# %% Create Tables for EXPERIMENT_INFO\n",
    "\n",
    "conn = psycopg2.connect(**kwargs)\n",
    "\n",
    "print(\"Connection Successful\")\n",
    "\n",
    "cur = conn.cursor()\n",
    "cur.execute(\n",
    "    '''\n",
    "    CREATE TABLE IF NOT EXISTS EXPERIMENT_INFO (\n",
    "        exp_id              SERIAL          PRIMARY KEY,\n",
    "        citation_type       VARCHAR(20),\n",
    "        meta                JSONB,\n",
    "        UNIQUE(citation_type, meta)\n",
    "    );\n",
    "    '''\n",
    ")\n",
    "\n",
    "print(\"Table(s) created successfully\")\n",
    "conn.commit()\n",
    "\n",
    "print(\"Operation successful\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I left off talking about inserting new tuples that already exist... and violating key constraints. What about sequencing?\n",
    "## Let's insert like 5 doi's, see what happens"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

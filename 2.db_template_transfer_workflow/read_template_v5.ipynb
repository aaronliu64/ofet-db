{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "448883ff",
   "metadata": {},
   "source": [
    "## Python Code to Extract Data From Template and Transfer to PostGRE SQL\n",
    "#### Authors : Aaron Liu, Rahul Venkatesh, Jessica Bonsu, Myeongyeon Lee \n",
    "##### Date Edited : 06-07-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33385d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Required Packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2 as pg\n",
    "\n",
    "import os\n",
    "from psycopg2.extras import Json\n",
    "from psycopg2.extensions import AsIs\n",
    "import functools\n",
    "import json\n",
    "import sys\n",
    "\n",
    "import requests\n",
    "# import bibtexparser\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f7f8941",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Required Functions To Extract Information from Template\n",
    "\n",
    "# Function to remove rows that have no value (NaN) in the second column\n",
    "def remove_emptyrows(df):\n",
    "    nan_mask = ~df.iloc[:,1].isna() \n",
    "    return df[nan_mask]\n",
    "\n",
    "# Function to convert a sheet into dictionary data type\n",
    "def read_sheet(filepath, sheet_name, ordering=False, usecols=\"A,B,D\", meas=False):\n",
    "\n",
    "    ## NOTE: ADD AN ARGUMENT TO DECIDE WHETHER OR NOT TO BRACKET THE SHEET\n",
    "    ## NOTE : The argument \"ordering\" is used for sheets like solution processing or substrate pretreatmant where the order of the processing step matters\n",
    "    ## NOTE : The argument \"usecols\" is to store information from particular columns in the excel sheet\n",
    "    ## NOTE : The argument \"meas\" is used to \n",
    "    \n",
    "    ## Read Sheet Information\n",
    "    df = pd.read_excel(\n",
    "        filepath,\n",
    "        sheet_name=sheet_name,\n",
    "        usecols=usecols\n",
    "    )\n",
    "    \n",
    "    # Call Function To Remove empty rows\n",
    "    df_ = remove_emptyrows(df)\n",
    "    \n",
    "    # Create an empty dictionary\n",
    "    sheet_dict = dict()\n",
    "\n",
    "    # To account for sheets where processing order is important\n",
    "    if ordering==True:\n",
    "        df_list = split_df(df_) #calls function split_df\n",
    "        for i, df in enumerate(df_list):\n",
    "            sheet_dict[i] = table_to_dict(df) #adds each table to the dictionary\n",
    "    else:\n",
    "        sheet_dict = table_to_dict(df_)\n",
    "    \n",
    "    return sheet_dict #returns a dataframe\n",
    "\n",
    "def split_df(df_):\n",
    "    #For sheets where processing order is important, this function finds tables with '#' in the name of the first column title and turns it into a df\n",
    "    \n",
    "    split_idx_mask = df_.iloc[:,0].str.contains('#') #Find the object splits\n",
    "    w = df_[split_idx_mask].index.values\n",
    "    \n",
    "    df_list = []\n",
    "    \n",
    "    for i in range(len(w)-1):\n",
    "        next_df = df_.loc[w[i]+1:w[i+1]-1,:]\n",
    "        df_list.append(next_df)    \n",
    "    \n",
    "    return df_list\n",
    "\n",
    "def table_to_dict(df_):\n",
    "    \n",
    "    main_mask = pd.isna(df_.JSON) # it flags rows that dont have a value for JSON column\n",
    "    step_dict = dict(df_[main_mask].iloc[:,:2].values) # Stores rows that have \"NaN\" for JSON column in df_ as dict\n",
    "\n",
    "    \n",
    "    \n",
    "    for json_field in pd.unique(df_.JSON): #read through unique JSON types (e.g. NaN, meta or data)\n",
    "\n",
    "        if pd.isna(json_field): #ignore fields with JSON type as NaN\n",
    "            continue\n",
    "            \n",
    "        # dictionary to store information with JSON type \"data\"\n",
    "        elif json_field=='data':\n",
    "            data_mask = df_.JSON=='data'\n",
    "            \n",
    "            # lump key:value pairs into a second nested data dict\n",
    "            step_dict['data'] = dict()\n",
    "            \n",
    "            for i, s in df_[data_mask].iterrows():\n",
    "                step_dict['data'][s[s.index[0]]] = s['value':'error_type'].dropna().to_dict()\n",
    "        else:\n",
    "            json_mask = df_.JSON==json_field\n",
    "            step_dict[json_field] = dict(df_[json_mask].iloc[:,:2].values) # creates a new key for JSON types like meta and params and adds its corresponding values to it \n",
    "\n",
    "    return step_dict\n",
    "\n",
    "# f = pd.ExcelFile(fpath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc11aca",
   "metadata": {},
   "source": [
    "### Reading and Extracting Data From Sheets in Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "65b4a51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading Data From Sheets in Template\n",
    "\n",
    "fpath = r'..\\db_feed\\v6_example_1_real.xlsx' #Add path for template file\n",
    "\n",
    "#Storing each sheet in the template file as a dictionary\n",
    "exp_info = read_sheet(fpath, 'Data Origin')\n",
    "solution_makeup = read_sheet(fpath, 'Solution Makeup', ordering=True)\n",
    "solution_processing = read_sheet(fpath, 'Solution Treatment', ordering=True)\n",
    "device_fab = read_sheet(fpath, 'Device Fabrication')\n",
    "substrate_pretreat = read_sheet(fpath, 'Substrate Pretreat', ordering=True)\n",
    "coating_process = read_sheet(fpath, 'Coating Process')\n",
    "post_process = read_sheet(fpath, 'Post-Processing', ordering=True)\n",
    "device_meas = read_sheet(fpath, 'Device Measurement', usecols=\"A:G\", ordering=True)\n",
    "other_meas = read_sheet(fpath, 'Other Measurements', usecols=\"A:G\", ordering=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9b493cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'entity_type': 'solution', 'concentration': 4},\n",
       " 1: {'entity_type': 'solvent',\n",
       "  'iupac_name': '1,2-dichlorobenzene',\n",
       "  'pubchem_cid': 7239,\n",
       "  'vol_frac': 1},\n",
       " 2: {'entity_type': 'polymer',\n",
       "  'common_name': 'DPP-DTT',\n",
       "  'iupac_name': 'poly[2,5-(2-octyldodecyl)-3,6-diketopyrrolopyrrole-alt-5,5-(2,5-di(thien-2-yl)thieno [3,2-b]thiophene)]',\n",
       "  'mn': 55,\n",
       "  'mw': 199,\n",
       "  'dispersity': 3.62,\n",
       "  'wt_frac': 0.6},\n",
       " 3: {'entity_type': 'polymer',\n",
       "  'common_name': 'PS',\n",
       "  'iupac_name': 'poly(styrene)',\n",
       "  'mn': 2.18,\n",
       "  'mw': 2.2,\n",
       "  'dispersity': 1.01,\n",
       "  'wt_frac': 0.4}}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use this code block to check how each sheet has been converted to a dictionary\n",
    "solution_makeup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e25e9f",
   "metadata": {},
   "source": [
    "### Transferring Information From Template To PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "02ea38c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postgres python\n",
    "from psycopg2.extras import Json \n",
    "\n",
    "# Adapters necessary for converting python data types to PostgreSQL compatible data types \n",
    "def addapt_numpy_float64(numpy_float64):\n",
    "    return AsIs(numpy_float64)\n",
    "\n",
    "def addapt_numpy_int64(numpy_int64):\n",
    "    return AsIs(numpy_int64)\n",
    "\n",
    "def nan_to_null(f,\n",
    "        _NULL=AsIs('NULL'),\n",
    "        _Float=pg.extensions.Float):\n",
    "    if not np.isnan(f):\n",
    "        return _Float(f)\n",
    "    return _NULL\n",
    "\n",
    "pg.extensions.register_adapter(np.float64, addapt_numpy_float64)\n",
    "pg.extensions.register_adapter(np.int64, addapt_numpy_int64)\n",
    "pg.extensions.register_adapter(float, nan_to_null)\n",
    "\n",
    "param_dict = {\n",
    "    \"host\"      : \"127.0.0.1\",\n",
    "    \"database\"  : \"ofetdb_testenv_RV\",\n",
    "    \"user\"      : \"postgres\",\n",
    "    \"password\"  : \"Rahul2411!\",\n",
    "    \"port\"      : \"5432\",\n",
    "}\n",
    "\n",
    "def connect(params_dict):\n",
    "    \"\"\" Connect to the PostgreSQL database server \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        # connect to the PostgreSQL server\n",
    "        print('Connecting to the PostgreSQL database...')\n",
    "        conn = pg.connect(**params_dict)\n",
    "    except (Exception, pg.DatabaseError) as error:\n",
    "        print(error)\n",
    "        sys.exit(1) \n",
    "    print(\"Connection successful\")\n",
    "    return conn\n",
    "\n",
    "def pg_query(sql, tup):\n",
    "    \n",
    "    try:\n",
    "        # Database connection\n",
    "        conn = connect(param_dict)\n",
    "        cur = conn.cursor()\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Pass SQL query, using string and placeholders\n",
    "        cur.execute(sql, tup)\n",
    "        \n",
    "        # Fetch result\n",
    "        fetched = cur.fetchone()[0]\n",
    "        \n",
    "        # Commit result\n",
    "        conn.commit()\n",
    "        print(\"Operation Successful\")\n",
    "\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "        \n",
    "    except (Exception, pg.DatabaseError) as error:\n",
    "        # If database connection unsuccessful, then close connection \n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "    \n",
    "    return fetched #return query result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9a330338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg2.extras import Json\n",
    "\n",
    "def convert_entry(entry_dict):\n",
    "    \n",
    "    #This function reads a dictionary and extracts the column names and values from it\n",
    "    \n",
    "    pg_entry = entry_dict\n",
    "    for key in pg_entry.keys():\n",
    "        if type(pg_entry[key])==dict:\n",
    "            pg_entry[key]=Json(pg_entry[key])\n",
    "    columns = pg_entry.keys()\n",
    "    values = [pg_entry[column] for column in columns]\n",
    "    \n",
    "    return pg_entry, columns, values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f07a534",
   "metadata": {},
   "source": [
    "###### Doubt 1 : \n",
    "\n",
    "I made a new database. we were not able to add any new records to the old database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3b44f5",
   "metadata": {},
   "source": [
    "### 1.Checking and Storing Experiment Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6cdd7df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import _json\n",
    "\n",
    "exp_pg_entry, exp_columns, exp_values = convert_entry(exp_info)\n",
    "\n",
    "#print(type(pg_entry))\n",
    "#print(type(columns))\n",
    "#print(columns)\n",
    "#print(type(values))\n",
    "#print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "863fbff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "Connection successful\n",
      "Operation Successful\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = '''\n",
    "    INSERT INTO experiment_info (%s) \n",
    "    VALUES %s\n",
    "    ON CONFLICT (citation_type, meta) DO UPDATE\n",
    "    SET (%s) = %s\n",
    "    RETURNING exp_id\n",
    "    \n",
    "    '''\n",
    "tup = (AsIs(','.join(exp_columns)), tuple(exp_values), AsIs(','.join(exp_columns)), tuple(exp_values))\n",
    "\n",
    "\n",
    "\n",
    "exp_id = pg_query(sql, tup)\n",
    "exp_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "980adf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Dont forget to assign the exp_id to sample table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be3d4f8",
   "metadata": {},
   "source": [
    "### 2.Checking and Storing Solution Information (Polymer, Solvent, Solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7cf0704d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity_type': 'solution', 'concentration': 4}\n",
      "{'entity_type': 'solvent', 'iupac_name': '1,2-dichlorobenzene', 'pubchem_cid': 7239, 'vol_frac': 1}\n",
      "{'entity_type': 'polymer', 'common_name': 'DPP-DTT', 'iupac_name': 'poly[2,5-(2-octyldodecyl)-3,6-diketopyrrolopyrrole-alt-5,5-(2,5-di(thien-2-yl)thieno [3,2-b]thiophene)]', 'mn': 55, 'mw': 199, 'dispersity': 3.62, 'wt_frac': 0.6}\n"
     ]
    }
   ],
   "source": [
    "## Last stop - current code doesnt account for multiple polymers and solvents. work on that. Use the entity type.\n",
    "\n",
    "\n",
    "import psycopg2\n",
    "from psycopg2 import _json\n",
    "\n",
    "pg_entry, columns, values = convert_entry(solution_makeup)\n",
    "\n",
    "\n",
    "# Access the JSON data directly\n",
    "solution_data = values[0].adapted\n",
    "solvent_data = values[1].adapted\n",
    "polymer_data = values[2].adapted\n",
    "\n",
    "print(solution_data)\n",
    "print(solvent_data)\n",
    "#print(type(solvent_data))\n",
    "print(polymer_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa33392",
   "metadata": {},
   "source": [
    "###### 2.1 Storing Solvent Information in SOLVENT table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f303f158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pubchem_cid': 7239, 'iupac_name': '1,2-dichlorobenzene'}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "#Extracting only the required information for the SOLVENT table\n",
    "\n",
    "solvent_desired_keys = ['pubchem_cid', 'iupac_name','meta']\n",
    "\n",
    "SOLVENT_data = {key: solvent_data[key] for key in solvent_desired_keys if key in solvent_data}\n",
    "\n",
    "print(SOLVENT_data)\n",
    "print(type(SOLVENT_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "37cb6bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['pubchem_cid', 'iupac_name'])\n",
      "<class 'dict_keys'>\n",
      "[7239, '1,2-dichlorobenzene']\n",
      "<class 'list'>\n",
      "7239\n"
     ]
    }
   ],
   "source": [
    "#Extracting column and values information for the SOLVENT table\n",
    "\n",
    "pg_entry_solvent, solvent_columns, solvent_values = convert_entry(SOLVENT_data)\n",
    "\n",
    "print(solvent_columns)\n",
    "print(type(solvent_columns))\n",
    "print(solvent_values)\n",
    "print(type(solvent_values))\n",
    "print(solvent_values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c16072",
   "metadata": {},
   "source": [
    "###### DOUBT 2 \n",
    "\n",
    "Currently the SOLVENT table has a UNIQUE value assigned to it. Which means there can only be one chloroform. But what if we have two chlorforms from different vendors having diff meta information. Shouldnt we store both and assign each one an ID?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a9e8a3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "Connection successful\n",
      "Operation Successful\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7239"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert into SOLVENT table\n",
    "\n",
    "sql = '''\n",
    "    INSERT INTO SOLVENT (%s) \n",
    "    VALUES %s\n",
    "    ON CONFLICT (iupac_name, meta) DO UPDATE\n",
    "    SET (%s) = %s\n",
    "    RETURNING pubchem_cid\n",
    "    \n",
    "    '''\n",
    "tup = (AsIs(','.join(solvent_columns)), tuple(solvent_values), AsIs(','.join(solvent_columns)), tuple(solvent_values))\n",
    "\n",
    "\n",
    "\n",
    "pubchem_cid = pg_query(sql, tup)\n",
    "pubchem_cid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bbb36b",
   "metadata": {},
   "source": [
    "###### 2.2 Storing polymer Information in POLYMER table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bb487d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'common_name': 'DPP-DTT', 'iupac_name': 'poly[2,5-(2-octyldodecyl)-3,6-diketopyrrolopyrrole-alt-5,5-(2,5-di(thien-2-yl)thieno [3,2-b]thiophene)]', 'mw': 199, 'mn': 55, 'dispersity': 3.62}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "#Extracting only the required information for the POLYMER table\n",
    "\n",
    "polymer_desired_keys = ['common_name', 'iupac_name','mw','mn','dispersity','meta']\n",
    "\n",
    "POLYMER_data = {key: polymer_data[key] for key in polymer_desired_keys if key in polymer_data}\n",
    "\n",
    "print(POLYMER_data)\n",
    "print(type(POLYMER_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a78c916c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['common_name', 'iupac_name', 'mw', 'mn', 'dispersity'])\n",
      "<class 'dict_keys'>\n",
      "['DPP-DTT', 'poly[2,5-(2-octyldodecyl)-3,6-diketopyrrolopyrrole-alt-5,5-(2,5-di(thien-2-yl)thieno [3,2-b]thiophene)]', 199, 55, 3.62]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "#Extracting column and values information for the POLYMER table\n",
    "\n",
    "pg_entry_polymer, polymer_columns, polymer_values = convert_entry(POLYMER_data)\n",
    "\n",
    "print(polymer_columns)\n",
    "print(type(polymer_columns))\n",
    "print(polymer_values)\n",
    "print(type(polymer_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a122b775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "Connection successful\n",
      "Operation Successful\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert into POLYMER table\n",
    "\n",
    "sql = '''\n",
    "INSERT INTO POLYMER (%s) VALUES %s\n",
    "ON CONFLICT(common_name,iupac_name,Mn,Mw,dispersity,meta) DO UPDATE\n",
    "SET (%s) = %s\n",
    "RETURNING polymer_id\n",
    "'''\n",
    "\n",
    "tup = (AsIs(','.join(polymer_columns)), tuple(polymer_values), AsIs(','.join(polymer_columns)), tuple(polymer_values))\n",
    "\n",
    "\n",
    "polymer_id = pg_query(sql, tup)\n",
    "polymer_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc43b21",
   "metadata": {},
   "source": [
    "###### 2.3 Storing solution Information in SOLUTION table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ff5768b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'concentration': 4}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "#Extracting only the required information for the POLYMER table\n",
    "\n",
    "solution_desired_keys = ['concentration']\n",
    "\n",
    "SOLUTION_data = {key: solution_data[key] for key in solution_desired_keys if key in solution_data}\n",
    "\n",
    "print(SOLUTION_data)\n",
    "print(type(SOLUTION_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1201725c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['concentration'])\n",
      "<class 'dict_keys'>\n",
      "[4]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "#Extracting column and values information for the SOLUTION table\n",
    "\n",
    "pg_entry_solution, solution_columns, solution_values = convert_entry(SOLUTION_data)\n",
    "\n",
    "print(solution_columns)\n",
    "print(type(solution_columns))\n",
    "print(solution_values)\n",
    "print(type(solution_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1faaf133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "Connection successful\n",
      "Operation Successful\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert into SOLUTION table\n",
    "\n",
    "sql = '''\n",
    "INSERT INTO SOLUTION (%s) VALUES %s\n",
    "RETURNING solution_id\n",
    "'''\n",
    "\n",
    "tup = (AsIs(','.join(solution_columns)), tuple(solution_values))\n",
    "\n",
    "\n",
    "solution_id = pg_query(sql, tup)\n",
    "solution_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b188fc83",
   "metadata": {},
   "source": [
    "###### 2.4 Storing Solvent Information in SOLUTION_MAKEUP_SOLVENT table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "028ca7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vol_frac': 1}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "#Extracting the volume fraction information for the SOLUTION_MAKEUP_SOLVENT table\n",
    "\n",
    "solution_makeup_solvent_desired_keys = ['vol_frac']\n",
    "\n",
    "SOLUTION_MAKEUP_SOLVENT_data = {key: solvent_data[key] for key in solution_makeup_solvent_desired_keys if key in solvent_data}\n",
    "\n",
    "print(SOLUTION_MAKEUP_SOLVENT_data)\n",
    "print(type(SOLUTION_MAKEUP_SOLVENT_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "58f7419e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['vol_frac'])\n",
      "<class 'dict_keys'>\n",
      "[1]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "#Extracting column and values information for the SOLUTION_MAKEUP_SOLVENT table\n",
    "\n",
    "pg_entry_solution_makeup_solvent, solution_makeup_solvent_columns, solution_makeup_solvent_values = convert_entry(SOLUTION_MAKEUP_SOLVENT_data)\n",
    "\n",
    "print(solution_makeup_solvent_columns)\n",
    "print(type(solution_makeup_solvent_columns))\n",
    "print(solution_makeup_solvent_values)\n",
    "print(type(solution_makeup_solvent_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7369b1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert into SOLUTION_MAKEUP_SOLVENT table\n",
    "\n",
    "import psycopg2\n",
    "\n",
    "# Establish a connection to the PostgreSQL database\n",
    "conn = pg.connect(**param_dict)\n",
    "\n",
    "# Create a cursor object to interact with the database\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Define the record values to be inserted\n",
    "vol_frac = solution_makeup_solvent_values[0]\n",
    "\n",
    "# Get the solution_id from the SOLUTION table\n",
    "select_solution_query = '''\n",
    "    SELECT solution_id FROM SOLUTION\n",
    "'''\n",
    "\n",
    "cur.execute(select_solution_query)\n",
    "solution_result = cur.fetchone()\n",
    "if solution_result is not None:\n",
    "    solution_id = solution_result[0]\n",
    "\n",
    "    # Get the solvent_id from the SOLVENT table\n",
    "    select_solvent_query = '''\n",
    "        SELECT pubchem_cid FROM SOLVENT\n",
    "    '''\n",
    "\n",
    "    cur.execute(select_solvent_query)\n",
    "    solvent_result = cur.fetchone()\n",
    "    if solvent_result is not None:\n",
    "        solvent_id = solvent_result[0]\n",
    "\n",
    "        # Define the SQL query to insert a record into the SOLUTION_MAKEUP_SOLVENT table\n",
    "        insert_query = '''\n",
    "            INSERT INTO SOLUTION_MAKEUP_SOLVENT (solution_id, solvent_id, vol_frac)\n",
    "            VALUES (%s, %s, %s)\n",
    "        '''\n",
    "\n",
    "        # Execute the SQL query to insert the record\n",
    "        cur.execute(insert_query, (solution_id, solvent_id, vol_frac))\n",
    "\n",
    "        # Commit the changes to the database\n",
    "        conn.commit()\n",
    "\n",
    "# Close the cursor and connection\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ff0b02",
   "metadata": {},
   "source": [
    "###### 2.5 Storing polymer Information in SOLUTION_MAKEUP_POLYMER table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fc9d8bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wt_frac': 1}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "#Extracting the wt fraction information for the SOLUTION_MAKEUP_POLYMER table\n",
    "\n",
    "solution_makeup_polymer_desired_keys = ['wt_frac']\n",
    "\n",
    "SOLUTION_MAKEUP_POLYMER_data = {key: polymer_data[key] for key in solution_makeup_polymer_desired_keys if key in polymer_data}\n",
    "\n",
    "print(SOLUTION_MAKEUP_POLYMER_data)\n",
    "print(type(SOLUTION_MAKEUP_POLYMER_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bdf4c765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['wt_frac'])\n",
      "<class 'dict_keys'>\n",
      "[1]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "#Extracting column and values information for the SOLUTION_MAKEUP_SOLVENT table\n",
    "\n",
    "pg_entry_solution_makeup_polymer, solution_makeup_polymer_columns, solution_makeup_polymer_values = convert_entry(SOLUTION_MAKEUP_POLYMER_data)\n",
    "\n",
    "print(solution_makeup_polymer_columns)\n",
    "print(type(solution_makeup_polymer_columns))\n",
    "print(solution_makeup_polymer_values)\n",
    "print(type(solution_makeup_polymer_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cb9777fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Establish a connection to the PostgreSQL database\n",
    "conn = pg.connect(**param_dict)\n",
    "\n",
    "# Create a cursor object to interact with the database\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Define the record values to be inserted\n",
    "wt_frac = solution_makeup_polymer_values[0]\n",
    "\n",
    "# Get the solution_id from the SOLUTION table\n",
    "select_solution_query = '''\n",
    "    SELECT solution_id FROM SOLUTION\n",
    "'''\n",
    "\n",
    "cur.execute(select_solution_query)\n",
    "solution_result = cur.fetchone()\n",
    "if solution_result is not None:\n",
    "    solution_id = solution_result[0]\n",
    "\n",
    "    # Get the polymer_id from the POLYMER table\n",
    "    select_polymer_query = '''\n",
    "        SELECT polymer_id FROM POLYMER\n",
    "    '''\n",
    "\n",
    "    cur.execute(select_polymer_query)\n",
    "    polymer_result = cur.fetchone()\n",
    "    if polymer_result is not None:\n",
    "        polymer_id = polymer_result[0]\n",
    "\n",
    "        # Define the SQL query to insert a record into the SOLUTION_MAKEUP_POLYMER table\n",
    "        insert_query = '''\n",
    "            INSERT INTO SOLUTION_MAKEUP_POLYMER (solution_id, polymer_id, wt_frac)\n",
    "            VALUES (%s, %s, %s)\n",
    "        '''\n",
    "\n",
    "        # Execute the SQL query to insert the record\n",
    "        cur.execute(insert_query, (solution_id, polymer_id, wt_frac))\n",
    "\n",
    "        # Commit the changes to the database\n",
    "        conn.commit()\n",
    "\n",
    "# Close the cursor and connection\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9acbf4c",
   "metadata": {},
   "source": [
    "### 3. Checking and Storing Device Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3afc6c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "<class 'dict_keys'>\n",
      "dict_keys(['params', 'meta'])\n",
      "<class 'list'>\n",
      "[<psycopg2._json.Json object at 0x000002A1122A7DA0>, <psycopg2._json.Json object at 0x000002A1122A7D68>]\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import _json\n",
    "\n",
    "device_fab_pg_entry, device_fab_columns, device_fab_values = convert_entry(device_fab)\n",
    "\n",
    "#print(type(device_fab_pg_entry))\n",
    "#print(type(device_fab_columns))\n",
    "print(device_fab_columns)\n",
    "print(type(device_fab_values))\n",
    "print(device_fab_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a7efaf7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "Connection successful\n",
      "Operation Successful\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = '''\n",
    "    INSERT INTO DEVICE_FABRICATION (%s) \n",
    "    VALUES %s\n",
    "    ON CONFLICT (params, meta) DO UPDATE\n",
    "    SET (%s) = %s\n",
    "    RETURNING device_fab_id\n",
    "    \n",
    "    '''\n",
    "tup = (AsIs(','.join(device_fab_columns)), tuple(device_fab_values), AsIs(','.join(device_fab_columns)), tuple(device_fab_values))\n",
    "\n",
    "\n",
    "\n",
    "device_fab_id = pg_query(sql, tup)\n",
    "device_fab_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f159e5a",
   "metadata": {},
   "source": [
    "### 4. Checking and Storing Film Deposition Information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d6a71e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['deposition_type'])\n",
      "<class 'list'>\n",
      "['spin']\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import _json\n",
    "\n",
    "coating_process_pg_entry, coating_process_columns, coating_process_values = convert_entry(coating_process)\n",
    "\n",
    "#print(type(coating_process_pg_entry))\n",
    "#print(type(coating_process_columns))\n",
    "print(coating_process_columns)\n",
    "print(type(coating_process_values))\n",
    "print(coating_process_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5dedb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Doubt : In the create OFET DB code why is film_deposition_id in unique?\n",
    "\n",
    "sql = '''\n",
    "    INSERT INTO FILM_DEPOSITION (%s) \n",
    "    VALUES %s\n",
    "    ON CONFLICT (deposition_type, params, meta) DO UPDATE\n",
    "    SET (%s) = %s\n",
    "    RETURNING device_fab_id\n",
    "    \n",
    "    '''\n",
    "tup = (AsIs(','.join(coating_process_columns)), tuple(coating_process_values), AsIs(','.join(coating_process_columns)), tuple(coating_process_values))\n",
    "\n",
    "\n",
    "\n",
    "film_deposition_id = pg_query(sql, tup)\n",
    "film_deposition_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a284be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ff4ddb1",
   "metadata": {},
   "source": [
    "### 5. Checking and Storing the subprocess recipes (Solution Treatment, Substrate Pretreatment, Post Process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f5d2a1",
   "metadata": {},
   "source": [
    "### 6. Checking and Storing information to the OFET_PROCESS TABLE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415b4865",
   "metadata": {},
   "source": [
    "### 7. Checking and Storing information to the SAMPLE TABLE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a087025e",
   "metadata": {},
   "source": [
    "### 8. Checking and Storing the measurement information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed1d5c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "f5a8b522aac8123589db0e64c73ca2530e0ffae51a117df4f813e361992c41db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e783683f",
   "metadata": {},
   "source": [
    "## Python Code to Extract Data From Template and Transfer to PostGRE SQL\n",
    "#### Authors : Aaron Liu, Rahul Venkatesh, Jessica Bonsu, Myeongyeon Lee \n",
    "##### Date Edited : 07-05-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89cb348d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Required Packages\n",
    "def required_packages():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import psycopg2 as pg\n",
    "    import os\n",
    "    from psycopg2.extras import Json\n",
    "    from psycopg2.extensions import AsIs\n",
    "    import functools\n",
    "    import json\n",
    "    import sys\n",
    "    import requests\n",
    "    import pprint\n",
    "    \n",
    "    print ('DONE') #remove when done\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27fa3b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Required Functions To Extract Information from Template\n",
    "def read_all_sheets(filepath):\n",
    "    def remove_emptyrows(df):\n",
    "        nan_mask = ~df.iloc[:, 1].isna()\n",
    "        return df[nan_mask]\n",
    "\n",
    "    def split_df(df_):\n",
    "        split_idx_mask = df_.iloc[:, 0].str.contains('#')\n",
    "        w = df_[split_idx_mask].index.values\n",
    "        df_list = []\n",
    "\n",
    "        for i in range(len(w)-1):\n",
    "            next_df = df_.loc[w[i]+1:w[i+1]-1, :]\n",
    "            df_list.append(next_df)\n",
    "\n",
    "        return df_list\n",
    "\n",
    "    def table_to_dict(df_):\n",
    "        main_mask = pd.isna(df_.JSON)\n",
    "        step_dict = dict(df_[main_mask].iloc[:, :2].values)\n",
    "\n",
    "        for json_field in pd.unique(df_.JSON):\n",
    "            if pd.isna(json_field):\n",
    "                continue\n",
    "            elif json_field == 'data':\n",
    "                data_mask = df_.JSON == 'data'\n",
    "                step_dict['data'] = dict()\n",
    "\n",
    "                for i, s in df_[data_mask].iterrows():\n",
    "                    step_dict['data'][s[s.index[0]]] = s['value':'error_type'].dropna().to_dict()\n",
    "            else:\n",
    "                json_mask = df_.JSON == json_field\n",
    "                step_dict[json_field] = dict(df_[json_mask].iloc[:, :2].values)\n",
    "\n",
    "        return step_dict\n",
    "\n",
    "    def read_sheet(filepath, sheet_name, ordering=False, usecols=\"A,B,D\", meas=False):\n",
    "        df = pd.read_excel(filepath, sheet_name=sheet_name, usecols=usecols)\n",
    "        df_ = remove_emptyrows(df)\n",
    "        sheet_dict = dict()\n",
    "\n",
    "        if ordering == True:\n",
    "            df_list = split_df(df_)\n",
    "            for i, df in enumerate(df_list):\n",
    "                sheet_dict[i] = table_to_dict(df)\n",
    "        else:\n",
    "            sheet_dict = table_to_dict(df_)\n",
    "            \n",
    "    #Storing each sheet in the template file as a dictionary\n",
    "    exp_info = read_sheet(filepath, 'Data Origin')\n",
    "    solution_makeup = read_sheet(filepath, 'Solution Makeup', ordering=True)\n",
    "    solution_processing = read_sheet(filepath, 'Solution Treatment', ordering=True)\n",
    "    device_fab = read_sheet(filepath, 'Device Fabrication')\n",
    "    substrate_pretreat = read_sheet(filepath, 'Substrate Pretreat', ordering=True)\n",
    "    coating_process = read_sheet(filepath, 'Coating Process')\n",
    "    post_process = read_sheet(filepath, 'Post-Processing', ordering=True)\n",
    "    device_meas = read_sheet(filepath, 'Device Measurement', usecols=\"A:G\", ordering=True)\n",
    "    other_meas = read_sheet(filepath, 'Other Measurements', usecols=\"A:G\", ordering=True)\n",
    "\n",
    "    return {\n",
    "        'exp_info': exp_info,\n",
    "        'solution_makeup': solution_makeup,\n",
    "        'solution_processing': solution_processing,\n",
    "        'device_fab': device_fab,\n",
    "        'substrate_pretreat': substrate_pretreat,\n",
    "        'coating_process': coating_process,\n",
    "        'post_process': post_process,\n",
    "        'device_meas': device_meas,\n",
    "        'other_meas': other_meas\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bc85e5",
   "metadata": {},
   "source": [
    "### Reading and Extracting Data From Sheets in Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e03872a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jbonsu3\\AppData\\Local\\anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "C:\\Users\\jbonsu3\\AppData\\Local\\anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "C:\\Users\\jbonsu3\\AppData\\Local\\anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "C:\\Users\\jbonsu3\\AppData\\Local\\anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "C:\\Users\\jbonsu3\\AppData\\Local\\anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "C:\\Users\\jbonsu3\\AppData\\Local\\anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "C:\\Users\\jbonsu3\\AppData\\Local\\anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "C:\\Users\\jbonsu3\\AppData\\Local\\anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "C:\\Users\\jbonsu3\\AppData\\Local\\anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    }
   ],
   "source": [
    "fpath =r'..\\db_feed\\v6_example_blend.xlsx' \n",
    "\n",
    "result = read_all_sheets(fpath)\n",
    "\n",
    "# Access the extracted information\n",
    "exp_info = result['exp_info']\n",
    "solution_makeup = result['solution_makeup']\n",
    "solution_processing = result['solution_processing']\n",
    "#...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9408213",
   "metadata": {},
   "source": [
    "### Transferring Information From Template To PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1838a522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postgres python\n",
    "\n",
    "# Adapters necessary for converting python data types to PostgreSQL compatible data types \n",
    "def register_pg_adapters():\n",
    "    def addapt_numpy_float64(numpy_float64):\n",
    "        return AsIs(numpy_float64)\n",
    "\n",
    "    def addapt_numpy_int64(numpy_int64):\n",
    "        return AsIs(numpy_int64)\n",
    "\n",
    "    def nan_to_null(f, _NULL=AsIs('NULL'), _Float=pg.extensions.Float):\n",
    "        if not np.isnan(f):\n",
    "            return _Float(f)\n",
    "        return _NULL\n",
    "\n",
    "    pg.extensions.register_adapter(np.float64, addapt_numpy_float64)\n",
    "    pg.extensions.register_adapter(np.int64, addapt_numpy_int64)\n",
    "    pg.extensions.register_adapter(float, nan_to_null)\n",
    "\n",
    "\n",
    "param_dict = {\n",
    "    \"host\"      : \"127.0.0.1\",\n",
    "    \"database\"  : \"ofetdb_testenv_RV\",\n",
    "    \"user\"      : \"postgres\",\n",
    "    \"password\"  : \"Rahul2411!\",\n",
    "    \"port\"      : \"5432\",\n",
    "}\n",
    "\n",
    "def connect(params_dict):\n",
    "    \"\"\" Connect to the PostgreSQL database server \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        # connect to the PostgreSQL server\n",
    "        print('Connecting to the PostgreSQL database...')\n",
    "        conn = pg.connect(**params_dict)\n",
    "    except (Exception, pg.DatabaseError) as error:\n",
    "        print(error)\n",
    "        sys.exit(1) \n",
    "    print(\"Connection successful\")\n",
    "    return conn\n",
    "\n",
    "def pg_query(sql, tup):\n",
    "    \n",
    "    try:\n",
    "        # Database connection\n",
    "        conn = connect(param_dict)\n",
    "        cur = conn.cursor()\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Pass SQL query, using string and placeholders\n",
    "        cur.execute(sql, tup)\n",
    "        \n",
    "        # Fetch result\n",
    "        fetched = cur.fetchone()[0]\n",
    "        \n",
    "        # Commit result\n",
    "        conn.commit()\n",
    "        print(\"Operation Successful\")\n",
    "\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "        \n",
    "    except (Exception, pg.DatabaseError) as error:\n",
    "        # If database connection unsuccessful, then close connection \n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "    \n",
    "    return fetched #return query result\n",
    "\n",
    "def convert_entry(entry_dict):\n",
    "    \n",
    "    #This function reads a dictionary and extracts the column names and values from it\n",
    "    \n",
    "    pg_entry = entry_dict\n",
    "    for key in pg_entry.keys():\n",
    "        if type(pg_entry[key])==dict:\n",
    "            pg_entry[key]=Json(pg_entry[key])\n",
    "    columns = pg_entry.keys()\n",
    "    values = [pg_entry[column] for column in columns]\n",
    "    \n",
    "    return pg_entry, columns, values\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import bibtexparser\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "# Given a valid doi string, return a dictionary of digital object information.\n",
    "def doi2dict(doi):\n",
    "    url = \"http://dx.doi.org/\" + doi\n",
    "    headers = {\"accept\": \"application/x-bibtex\"}\n",
    "    r = requests.get(url, headers=headers).text\n",
    "    bibdata = bibtexparser.bparser.BibTexParser().parse(r)\n",
    "    return bibdata.entries[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a043feae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import psycopg2\n",
    "from psycopg2 import _json\n",
    "\n",
    "\n",
    "### 1.Checking and Storing Experiment Information\n",
    "\n",
    "# using the doi to extract additional information if citation type is 'literature\n",
    "\n",
    "def store_experiment_info(exp_info, doi2dict):\n",
    "    if exp_info['citation_type'] == 'literature':\n",
    "        doi = exp_info['meta']['doi']\n",
    "        doi_info = doi2dict(doi)  # Fetch additional information using DOI\n",
    "\n",
    "        # Add the additional information to the existing dictionary\n",
    "        exp_info['meta'].update(doi_info)\n",
    "\n",
    "    exp_pg_entry, exp_columns, exp_values = convert_entry(exp_info)\n",
    "    sql = '''\n",
    "        INSERT INTO experiment_info (%s) \n",
    "        VALUES %s\n",
    "        ON CONFLICT (citation_type, meta) DO UPDATE\n",
    "        SET (%s) = %s\n",
    "        RETURNING exp_id\n",
    "        '''\n",
    "    tup = (AsIs(','.join(exp_columns)), tuple(exp_values), AsIs(','.join(exp_columns)), tuple(exp_values))\n",
    "    exp_id = pg_query(sql, tup)\n",
    "    print(\"Experiment information stored successfully with id: {}\".format(exp_id))\n",
    "\n",
    "\n",
    "import psycopg2\n",
    "import json\n",
    "\n",
    "def store_solution_makeup(solution_makeup, param_dict):\n",
    "    # Start transaction\n",
    "    conn = psycopg2.connect(**param_dict)\n",
    "\n",
    "    try:\n",
    "        with conn:\n",
    "            with conn.cursor() as cursor:\n",
    "                # Storing Solvent data - accounting for multiple solvents\n",
    "                solvent_data_filtered = [json_obj for json_obj in solution_makeup if json_obj.adapted.get(\"entity_type\") == \"solvent\"]\n",
    "\n",
    "                # Convert psycopg2._json.Json objects to JSON strings\n",
    "                solvent_data = [json_obj.adapted for json_obj in solvent_data_filtered]\n",
    "\n",
    "                # Storing Polymer data - accounting for multiple polymers\n",
    "                polymer_data_filtered = [json_obj for json_obj in solution_makeup if json_obj.adapted.get(\"entity_type\") == \"polymer\"]\n",
    "\n",
    "                # Convert psycopg2._json.Json objects to JSON strings\n",
    "                polymer_data = [json_obj.adapted for json_obj in polymer_data_filtered]\n",
    "\n",
    "                # Storing Solution Makeup data\n",
    "                solution_makeup_data = []\n",
    "                solution_makeup_data.append(solution_makeup[0].adapted)\n",
    "                solution_makeup_data.append(solvent_data)\n",
    "                solution_makeup_data.append(polymer_data)\n",
    "\n",
    "                # Extract solution information\n",
    "                solution_data = solution_makeup_data[0]\n",
    "                concentration = solution_data['concentration']\n",
    "\n",
    "                # Extract solvent information\n",
    "                solvent_data = solution_makeup_data[1]\n",
    "                solvent_ids = []\n",
    "                vol_fracs = []\n",
    "                for solvent in solvent_data:\n",
    "                    pubchem_cid = solvent['pubchem_cid']\n",
    "                    iupac_name = solvent['iupac_name']\n",
    "                    vol_frac = solvent['vol_frac']\n",
    "                    solvent_ids.append((pubchem_cid, iupac_name))\n",
    "                    vol_fracs.append(vol_frac)\n",
    "\n",
    "                # Extract polymer information\n",
    "                polymer_data = solution_makeup_data[2]\n",
    "                polymer_ids = []\n",
    "                wt_fracs = []\n",
    "                for polymer in polymer_data:\n",
    "                    common_name = polymer['common_name']\n",
    "                    iupac_name = polymer['iupac_name']\n",
    "                    mn = polymer['mn']\n",
    "                    mw = polymer['mw']\n",
    "                    dispersity = polymer['dispersity']\n",
    "                    wt_frac = polymer['wt_frac']\n",
    "                    meta = json.dumps(polymer['meta'])\n",
    "                    polymer_ids.append((common_name, iupac_name, mn, mw, dispersity, meta))\n",
    "                    wt_fracs.append(wt_frac)\n",
    "\n",
    "                # Check if the unique combination exists\n",
    "                select_solution_id_sql = '''\n",
    "                    SELECT sm.solution_id\n",
    "                    FROM SOLUTION_MAKEUP_SOLVENT sms\n",
    "                    JOIN SOLUTION_MAKEUP_POLYMER smp ON sms.solution_id = smp.solution_id\n",
    "                    JOIN SOLVENT s ON sms.solvent_id = s.pubchem_cid\n",
    "                    JOIN POLYMER p ON smp.polymer_id = p.polymer_id\n",
    "                    JOIN SOLUTION sm ON sms.solution_id = sm.solution_id\n",
    "                    WHERE sm.concentration = %s\n",
    "                    AND (s.pubchem_cid, s.iupac_name) IN %s\n",
    "                    AND (p.common_name, p.iupac_name, p.mn, p.mw, p.dispersity, p.meta) IN %s\n",
    "                    GROUP BY sm.solution_id\n",
    "                    HAVING COUNT(DISTINCT smp.polymer_id) = %s\n",
    "                    AND COUNT(DISTINCT sms.solvent_id) = %s\n",
    "                    AND ARRAY_AGG(sms.vol_frac) = %s::double precision[]\n",
    "                    AND ARRAY_AGG(smp.wt_frac) = %s::double precision[]\n",
    "                '''\n",
    "\n",
    "                cursor.execute(select_solution_id_sql, (concentration, tuple(solvent_ids), tuple(polymer_ids), len(polymer_ids), len(solvent_ids), vol_fracs, wt_fracs))\n",
    "                existing_solution = cursor.fetchone()\n",
    "\n",
    "                #Checking if there is an existing solution\n",
    "                if existing_solution:\n",
    "                    solution_id = existing_solution[0]\n",
    "                else:\n",
    "                    # Insert into SOLUTION table\n",
    "                    insert_solution_sql = '''\n",
    "                        INSERT INTO SOLUTION (concentration)\n",
    "                        VALUES (%s)\n",
    "                        RETURNING solution_id\n",
    "                    '''\n",
    "                    cursor.execute(insert_solution_sql, (concentration,))\n",
    "                    solution_id = cursor.fetchone()[0]\n",
    "\n",
    "                # Read Solvent data\n",
    "                for solvent_id, vol_frac in zip(solvent_ids, vol_fracs):\n",
    "                    pubchem_cid, iupac_name = solvent_id\n",
    "\n",
    "                    # Check if the solvent exists\n",
    "                    select_solvent_id_sql = '''\n",
    "                        SELECT pubchem_cid\n",
    "                        FROM SOLVENT\n",
    "                        WHERE iupac_name = %s\n",
    "                    '''\n",
    "                    cursor.execute(select_solvent_id_sql, (iupac_name,))\n",
    "                    existing_solvent = cursor.fetchone()\n",
    "\n",
    "                    if existing_solvent:\n",
    "                        solvent_id = existing_solvent[0]\n",
    "                    else:\n",
    "                        # Insert into SOLVENT table\n",
    "                        insert_solvent_sql = '''\n",
    "                            INSERT INTO SOLVENT (pubchem_cid, iupac_name)\n",
    "                            VALUES (%s, %s)\n",
    "                            RETURNING pubchem_cid\n",
    "                        '''\n",
    "                        cursor.execute(insert_solvent_sql, (pubchem_cid, iupac_name))\n",
    "                        solvent_id = cursor.fetchone()[0]\n",
    "\n",
    "                    # Insert or update SOLUTION_MAKEUP_SOLVENT table\n",
    "                    insert_solution_makeup_solvent_sql = '''\n",
    "                        INSERT INTO SOLUTION_MAKEUP_SOLVENT (solution_id, solvent_id, vol_frac)\n",
    "                        VALUES (%s, %s, %s)\n",
    "                        ON CONFLICT (solution_id, solvent_id, vol_frac) DO UPDATE\n",
    "                        SET solution_id = SOLUTION_MAKEUP_SOLVENT.solution_id,\n",
    "                            solvent_id = SOLUTION_MAKEUP_SOLVENT.solvent_id,\n",
    "                            vol_frac = SOLUTION_MAKEUP_SOLVENT.vol_frac\n",
    "                    '''\n",
    "                    cursor.execute(insert_solution_makeup_solvent_sql, (solution_id, solvent_id, vol_frac))\n",
    "\n",
    "                # Read the polymer data\n",
    "                for polymer_id, wt_frac in zip(polymer_ids, wt_fracs):\n",
    "                    common_name, iupac_name, mn, mw, dispersity, meta = polymer_id\n",
    "\n",
    "                    # Check if the polymer exists\n",
    "                    select_polymer_id_sql = '''\n",
    "                        SELECT polymer_id\n",
    "                        FROM POLYMER\n",
    "                        WHERE common_name = %s\n",
    "                        AND iupac_name = %s\n",
    "                        AND mn = %s\n",
    "                        AND mw = %s\n",
    "                        AND dispersity = %s\n",
    "                        AND meta = %s::jsonb\n",
    "                    '''\n",
    "                    cursor.execute(select_polymer_id_sql, (common_name, iupac_name, mn, mw, dispersity, meta))\n",
    "                    existing_polymer = cursor.fetchone()\n",
    "\n",
    "                    if existing_polymer:\n",
    "                        polymer_id = existing_polymer[0]\n",
    "                    else:\n",
    "                        # Insert into POLYMER table\n",
    "                        insert_polymer_sql = '''\n",
    "                            INSERT INTO POLYMER (common_name, iupac_name, mn, mw, dispersity, meta)\n",
    "                            VALUES (%s, %s, %s, %s, %s, %s::jsonb)\n",
    "                            RETURNING polymer_id\n",
    "                        '''\n",
    "                        cursor.execute(insert_polymer_sql, (common_name, iupac_name, mn, mw, dispersity, meta))\n",
    "                        polymer_id = cursor.fetchone()[0]\n",
    "\n",
    "                    # Insert or update SOLUTION_MAKEUP_POLYMER table\n",
    "                    insert_solution_makeup_polymer_sql = '''\n",
    "                        INSERT INTO SOLUTION_MAKEUP_POLYMER (solution_id, polymer_id, wt_frac)\n",
    "                        VALUES (%s, %s, %s)\n",
    "                        ON CONFLICT (solution_id, polymer_id, wt_frac) DO UPDATE\n",
    "                        SET solution_id = SOLUTION_MAKEUP_POLYMER.solution_id,\n",
    "                            polymer_id = SOLUTION_MAKEUP_POLYMER.polymer_id,\n",
    "                            wt_frac = SOLUTION_MAKEUP_POLYMER.wt_frac\n",
    "                    '''\n",
    "                    cursor.execute(insert_solution_makeup_polymer_sql, (solution_id, polymer_id, wt_frac))\n",
    "\n",
    "                print(\"Solution makeup information saved successfully with id : {}\".format(solution_id))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", str(e))\n",
    "\n",
    "    # Close the database connection\n",
    "    conn.close()\n",
    "\n",
    "# Usage example:\n",
    "store_solution_makeup(solution_makeup, param_dict)\n",
    "\n",
    "import psycopg2\n",
    "import json\n",
    "\n",
    "def store_device_fabrication(device_fab, param_dict):\n",
    "    # Start transaction\n",
    "    conn = psycopg2.connect(**param_dict)\n",
    "\n",
    "    try:\n",
    "        with conn:\n",
    "            with conn.cursor() as cursor:\n",
    "                # Convert device fabrication entry to columns and values\n",
    "                device_fab_pg_entry, device_fab_columns, device_fab_values = convert_entry(device_fab)\n",
    "\n",
    "                # If meta information is missing, add it as an empty dictionary\n",
    "                device_fab_columns_list = list(device_fab_columns)\n",
    "                if 'meta' not in device_fab_columns_list:\n",
    "                    device_fab_columns_list.append('meta')\n",
    "                    device_fab_values.append({})\n",
    "\n",
    "                # Convert values to JSON strings if they are dictionaries\n",
    "                device_fab_values = [json.dumps(value) if isinstance(value, dict) else value for value in device_fab_values]\n",
    "\n",
    "                # Insert into DEVICE_FABRICATION table\n",
    "                sql = '''\n",
    "                    INSERT INTO DEVICE_FABRICATION (%s) \n",
    "                    VALUES %s\n",
    "                    ON CONFLICT (params, meta) DO UPDATE\n",
    "                    SET (%s) = %s\n",
    "                    RETURNING device_fab_id\n",
    "                '''\n",
    "                tup = (AsIs(','.join(device_fab_columns_list)), tuple(device_fab_values), AsIs(','.join(device_fab_columns_list)), tuple(device_fab_values))\n",
    "                cursor.execute(sql, tup)\n",
    "                device_fab_id = cursor.fetchone()[0]\n",
    "\n",
    "                print(\"Device fabrication information saved successfully with id: {}\".format(device_fab_id))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", str(e))\n",
    "\n",
    "    # Close the database connection\n",
    "    conn.close()\n",
    "\n",
    "# Usage example:\n",
    "store_device_fabrication(device_fab, param_dict)\n",
    "import psycopg2\n",
    "import json\n",
    "\n",
    "def store_film_deposition(coating_process, param_dict):\n",
    "    # Start transaction\n",
    "    conn = psycopg2.connect(**param_dict)\n",
    "\n",
    "    try:\n",
    "        with conn:\n",
    "            with conn.cursor() as cursor:\n",
    "                # Convert coating process entry to columns and values\n",
    "                coating_process_pg_entry, coating_process_columns, coating_process_values = convert_entry(coating_process)\n",
    "\n",
    "                # If meta information is missing, add it as an empty dictionary\n",
    "                coating_process_columns_list = list(coating_process_columns)\n",
    "                if 'meta' not in coating_process_columns_list:\n",
    "                    coating_process_columns_list.append('meta')\n",
    "                    coating_process_values.append({})\n",
    "\n",
    "                # Convert values to JSON strings if they are dictionaries\n",
    "                coating_process_values = [json.dumps(value) if isinstance(value, dict) else value for value in coating_process_values]\n",
    "\n",
    "                # Insert into FILM_DEPOSITION table\n",
    "                sql = '''\n",
    "                    INSERT INTO FILM_DEPOSITION (%s) \n",
    "                    VALUES %s\n",
    "                    ON CONFLICT (deposition_type, params, meta) DO UPDATE\n",
    "                    SET (%s) = %s\n",
    "                    RETURNING film_deposition_id\n",
    "                '''\n",
    "                tup = (AsIs(','.join(coating_process_columns_list)), tuple(coating_process_values), AsIs(','.join(coating_process_columns_list)), tuple(coating_process_values))\n",
    "                cursor.execute(sql, tup)\n",
    "                film_deposition_id = cursor.fetchone()[0]\n",
    "\n",
    "                print(\"Film deposition information saved successfully with id: {}\".format(film_deposition_id))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", str(e))\n",
    "\n",
    "    # Close the database connection\n",
    "    conn.close()\n",
    "\n",
    "# Usage example:\n",
    "store_film_deposition(coating_process, param_dict)\n",
    "\n",
    "### 5. Checking and Storing the subprocess recipes (Solution Treatment, Substrate Pretreatment, Post Process)\n",
    "#### 5.1 SOLUTION TREATMENT\n",
    "\n",
    "def store_solution_treatment(param_dict, solution_processing):\n",
    "    # Function to insert data into SOLUTION_TREATMENT_STEP table\n",
    "    def insert_into_solution_treatment_step(cur, treatment_type, params, meta):\n",
    "        # Check if the record already exists\n",
    "        cur.execute(\n",
    "            \"SELECT solution_treatment_step_id FROM SOLUTION_TREATMENT_STEP WHERE treatment_type = %s AND params = %s::jsonb AND meta = %s::jsonb\",\n",
    "            (treatment_type, params, meta)\n",
    "        )\n",
    "        existing_id = cur.fetchone()\n",
    "\n",
    "        if existing_id:\n",
    "            solution_treatment_step_id = existing_id[0]\n",
    "        else:\n",
    "            # Insert data into SOLUTION_TREATMENT_STEP table\n",
    "            cur.execute(\n",
    "                \"INSERT INTO SOLUTION_TREATMENT_STEP (treatment_type, params, meta) VALUES (%s, %s::jsonb, %s::jsonb) RETURNING solution_treatment_step_id\",\n",
    "                (treatment_type, params, meta)\n",
    "            )\n",
    "            solution_treatment_step_id = cur.fetchone()[0]\n",
    "\n",
    "        return solution_treatment_step_id\n",
    "\n",
    "    # Function to insert data into SOLUTION_TREATMENT_ORDER table\n",
    "    def insert_into_solution_treatment_order(cur, solution_treatment_id, process_order, solution_treatment_step_id):\n",
    "        # Check if the record already exists\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            SELECT solution_treatment_id\n",
    "            FROM SOLUTION_TREATMENT_ORDER\n",
    "            WHERE solution_treatment_id = %s\n",
    "            AND process_order = %s\n",
    "            AND solution_treatment_step_id = %s\n",
    "            \"\"\",\n",
    "            (solution_treatment_id, process_order, solution_treatment_step_id)\n",
    "        )\n",
    "        existing_combination = cur.fetchone()\n",
    "\n",
    "        if not existing_combination:\n",
    "            # Insert new record into SOLUTION_TREATMENT_ORDER table\n",
    "            cur.execute(\n",
    "                \"INSERT INTO SOLUTION_TREATMENT_ORDER (solution_treatment_id, process_order, solution_treatment_step_id) VALUES (%s, %s, %s)\",\n",
    "                (solution_treatment_id, process_order, solution_treatment_step_id)\n",
    "            )\n",
    "\n",
    "        return solution_treatment_id\n",
    "\n",
    "    # Establish a connection to the PostgreSQL database\n",
    "    conn = psycopg2.connect(**param_dict)\n",
    "\n",
    "    # Create a cursor object to interact with the database\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    solution_treatment_id = None\n",
    "\n",
    "    for treatment in solution_processing.values():\n",
    "        # Convert params and meta to JSON format\n",
    "        params_json = json.dumps(treatment.get('params', {}))\n",
    "        meta_json = json.dumps(treatment.get('meta', {}))\n",
    "\n",
    "        # Insert data into SOLUTION_TREATMENT_STEP table\n",
    "        solution_treatment_step_id = insert_into_solution_treatment_step(cur, treatment['treatment_type'], params_json, meta_json)\n",
    "\n",
    "        if solution_treatment_id is None:\n",
    "            # Check if the record already exists in SOLUTION_TREATMENT table\n",
    "            cur.execute(\n",
    "                \"SELECT solution_treatment_id FROM SOLUTION_TREATMENT WHERE solution_treatment_id IN (SELECT solution_treatment_id FROM SOLUTION_TREATMENT_ORDER WHERE solution_treatment_step_id = %s)\",\n",
    "                (solution_treatment_step_id,)\n",
    "            )\n",
    "            existing_id = cur.fetchone()\n",
    "\n",
    "            if existing_id:\n",
    "                solution_treatment_id = existing_id[0]\n",
    "            else:\n",
    "                # Insert data into SOLUTION_TREATMENT table\n",
    "                cur.execute(\n",
    "                    \"INSERT INTO SOLUTION_TREATMENT (solution_treatment_id) VALUES (DEFAULT) RETURNING solution_treatment_id\"\n",
    "                )\n",
    "                solution_treatment_id = cur.fetchone()[0]\n",
    "\n",
    "        # Insert data into SOLUTION_TREATMENT_ORDER table\n",
    "        solution_treatment_id = insert_into_solution_treatment_order(cur, solution_treatment_id, treatment['process_step'], solution_treatment_step_id)\n",
    "\n",
    "    # Commit the changes to the database\n",
    "    print(\"Solution treatment saved successfully with id : {}\".format(solution_treatment_id))\n",
    "    conn.commit()\n",
    "\n",
    "    # Close the cursor and connection\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "###### 5.2 SUBSTRATE PRETREATMENT\n",
    "\n",
    "# Function to insert data into SUBSTRATE_PRETREAT_STEP table\n",
    "import psycopg2\n",
    "import json\n",
    "\n",
    "def store_substrate_pretreatment(param_dict, substrate_pretreat):\n",
    "    # Function to insert data into SUBSTRATE_PRETREAT_STEP table\n",
    "    def insert_into_substrate_pretreat_step(cur, treatment_type, params, meta):\n",
    "        # Check if the record already exists\n",
    "        cur.execute(\n",
    "            \"SELECT substrate_pretreat_step_id FROM SUBSTRATE_PRETREAT_STEP WHERE treatment_type = %s AND params = %s::jsonb AND meta = %s::jsonb\",\n",
    "            (treatment_type, params, meta)\n",
    "        )\n",
    "        existing_id = cur.fetchone()\n",
    "\n",
    "        if existing_id:\n",
    "            substrate_pretreat_step_id = existing_id[0]\n",
    "        else:\n",
    "            # Insert data into SUBSTRATE_PRETREAT_STEP table\n",
    "            cur.execute(\n",
    "                \"INSERT INTO SUBSTRATE_PRETREAT_STEP (treatment_type, params, meta) VALUES (%s, %s::jsonb, %s::jsonb) RETURNING substrate_pretreat_step_id\",\n",
    "                (treatment_type, params, meta)\n",
    "            )\n",
    "            substrate_pretreat_step_id = cur.fetchone()[0]\n",
    "\n",
    "        return substrate_pretreat_step_id\n",
    "\n",
    "    # Function to insert data into SUBSTRATE_PRETREAT_ORDER table\n",
    "    def insert_into_substrate_pretreat_order(cur, substrate_pretreat_id, process_order, substrate_pretreat_step_id):\n",
    "        # Check if the record already exists\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            SELECT substrate_pretreat_id\n",
    "            FROM SUBSTRATE_PRETREAT_ORDER\n",
    "            WHERE substrate_pretreat_id = %s\n",
    "            AND process_order = %s\n",
    "            AND substrate_pretreat_step_id = %s\n",
    "            \"\"\",\n",
    "            (substrate_pretreat_id, process_order, substrate_pretreat_step_id)\n",
    "        )\n",
    "        existing_combination = cur.fetchone()\n",
    "\n",
    "        if not existing_combination:\n",
    "            # Insert new record into SUBSTRATE_PRETREAT_ORDER table\n",
    "            cur.execute(\n",
    "                \"INSERT INTO SUBSTRATE_PRETREAT_ORDER (substrate_pretreat_id, process_order, substrate_pretreat_step_id) VALUES (%s, %s, %s)\",\n",
    "                (substrate_pretreat_id, process_order, substrate_pretreat_step_id)\n",
    "            )\n",
    "\n",
    "        return substrate_pretreat_id\n",
    "\n",
    "    # Establish a connection to the PostgreSQL database\n",
    "    conn = psycopg2.connect(**param_dict)\n",
    "\n",
    "    # Create a cursor object to interact with the database\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    substrate_pretreat_id = None\n",
    "\n",
    "    for treatment in substrate_pretreat.values():\n",
    "        # Convert params and meta to JSON format\n",
    "        params_json = json.dumps(treatment.get('params', {}))\n",
    "        meta_json = json.dumps(treatment.get('meta', {}))\n",
    "\n",
    "        # Insert data into SUBSTRATE_PRETREAT_STEP table\n",
    "        substrate_pretreat_step_id = insert_into_substrate_pretreat_step(cur, treatment['treatment_type'], params_json, meta_json)\n",
    "\n",
    "        if substrate_pretreat_id is None:\n",
    "            # Check if the record already exists in SUBSTRATE_PRETREAT table\n",
    "            cur.execute(\n",
    "                \"SELECT substrate_pretreat_id FROM SUBSTRATE_PRETREAT WHERE substrate_pretreat_id IN (SELECT substrate_pretreat_id FROM SUBSTRATE_PRETREAT_ORDER WHERE substrate_pretreat_step_id = %s)\",\n",
    "                (substrate_pretreat_step_id,)\n",
    "            )\n",
    "            existing_id = cur.fetchone()\n",
    "\n",
    "            if existing_id:\n",
    "                substrate_pretreat_id = existing_id[0]\n",
    "            else:\n",
    "                # Insert data into SUBSTRATE_PRETREAT table\n",
    "                cur.execute(\n",
    "                    \"INSERT INTO SUBSTRATE_PRETREAT (substrate_pretreat_id) VALUES (DEFAULT) RETURNING substrate_pretreat_id\"\n",
    "                )\n",
    "                substrate_pretreat_id = cur.fetchone()[0]\n",
    "\n",
    "        # Insert data into SUBSTRATE_PRETREAT_ORDER table\n",
    "        substrate_pretreat_id = insert_into_substrate_pretreat_order(cur, substrate_pretreat_id, treatment['process_step'], substrate_pretreat_step_id)\n",
    "\n",
    "    # Commit the changes to the database\n",
    "    print(\"Substrate pretreatment saved successfully with id : {}\".format(substrate_pretreat_id))\n",
    "    conn.commit()\n",
    "\n",
    "    # Close the cursor and connection\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "###### 5.3 POST PROCESSING TREATMENT\n",
    "# Function to insert data into POSTPROCESS_STEP table\n",
    "def insert_into_postprocess_step(cur, treatment_type, params, meta):\n",
    "    # Check if the record already exists\n",
    "    cur.execute(\n",
    "        \"SELECT postprocess_step_id FROM POSTPROCESS_STEP WHERE treatment_type = %s AND params = %s::jsonb AND meta = %s::jsonb\",\n",
    "        (treatment_type, params, meta)\n",
    "    )\n",
    "    existing_id = cur.fetchone()\n",
    "\n",
    "    if existing_id:\n",
    "        postprocess_step_id = existing_id[0]\n",
    "    else:\n",
    "        # Insert data into POSTPROCESS_STEP table\n",
    "        cur.execute(\n",
    "            \"INSERT INTO POSTPROCESS_STEP (treatment_type, params, meta) VALUES (%s, %s::jsonb, %s::jsonb) RETURNING postprocess_step_id\",\n",
    "            (treatment_type, params, meta)\n",
    "        )\n",
    "        postprocess_step_id = cur.fetchone()[0]\n",
    "\n",
    "    return postprocess_step_id\n",
    "\n",
    "# Function to insert data into POSTPROCESS_ORDER table\n",
    "def insert_into_postprocess_order(cur, postprocess_id, process_order, postprocess_step_id):\n",
    "    # Check if the record already exists\n",
    "    cur.execute(\n",
    "        \"\"\"\n",
    "        SELECT postprocess_id\n",
    "        FROM POSTPROCESS_ORDER\n",
    "        WHERE postprocess_id = %s\n",
    "        AND process_order = %s\n",
    "        AND postprocess_step_id = %s\n",
    "        \"\"\",\n",
    "        (postprocess_id, process_order, postprocess_step_id)\n",
    "    )\n",
    "    existing_combination = cur.fetchone()\n",
    "\n",
    "    if not existing_combination:\n",
    "        # Insert new record into POSTPROCESS_ORDER table\n",
    "        cur.execute(\n",
    "            \"INSERT INTO POSTPROCESS_ORDER (postprocess_id, process_order, postprocess_step_id) VALUES (%s, %s, %s)\",\n",
    "            (postprocess_id, process_order, postprocess_step_id)\n",
    "        )\n",
    "\n",
    "    return postprocess_id\n",
    "\n",
    "# Establish a connection to the PostgreSQL database\n",
    "conn = psycopg2.connect(**param_dict)\n",
    "\n",
    "# Create a cursor object to interact with the database\n",
    "cur = conn.cursor()\n",
    "\n",
    "postprocess_id = None\n",
    "\n",
    "for treatment in post_process.values():\n",
    "    # Convert params and meta to JSON format\n",
    "    params_json = json.dumps(treatment.get('params', {}))\n",
    "    meta_json = json.dumps(treatment.get('meta', {}))\n",
    "\n",
    "    # Insert data into POSTPROCESS_STEP table\n",
    "    postprocess_step_id = insert_into_postprocess_step(cur, treatment['treatment_type'], params_json, meta_json)\n",
    "\n",
    "    if postprocess_id is None:\n",
    "        # Check if the record already exists in POSTPROCESS table\n",
    "        cur.execute(\n",
    "            \"SELECT postprocess_id FROM POSTPROCESS WHERE postprocess_id IN (SELECT postprocess_id FROM POSTPROCESS_ORDER WHERE postprocess_step_id = %s)\",\n",
    "            (postprocess_step_id,)\n",
    "        )\n",
    "        existing_id = cur.fetchone()\n",
    "\n",
    "        if existing_id:\n",
    "            postprocess_id = existing_id[0]\n",
    "        else:\n",
    "            # Insert data into POSTPROCESS table\n",
    "            cur.execute(\n",
    "                \"INSERT INTO POSTPROCESS (postprocess_id) VALUES (DEFAULT) RETURNING postprocess_id\"\n",
    "            )\n",
    "            postprocess_id = cur.fetchone()[0]\n",
    "\n",
    "    # Insert data into POSTPROCESS_ORDER table\n",
    "    postprocess_id = insert_into_postprocess_order(cur, postprocess_id, treatment['process_step'], postprocess_step_id)\n",
    "\n",
    "# Commit the changes to the database\n",
    "print(\"Post Process treatment saved successfully with id : {}\".format(postprocess_id))\n",
    "conn.commit()\n",
    "\n",
    "# Close the cursor and connection\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "### 6. Checking and Storing information to the OFET_PROCESS TABLE and generating process_id\n",
    "import psycopg2\n",
    "import json\n",
    "\n",
    "def store_post_process_treatment(param_dict, post_process):\n",
    "    # Function to insert data into POSTPROCESS_STEP table\n",
    "    def insert_into_postprocess_step(cur, treatment_type, params, meta):\n",
    "        # Check if the record already exists\n",
    "        cur.execute(\n",
    "            \"SELECT postprocess_step_id FROM POSTPROCESS_STEP WHERE treatment_type = %s AND params = %s::jsonb AND meta = %s::jsonb\",\n",
    "            (treatment_type, params, meta)\n",
    "        )\n",
    "        existing_id = cur.fetchone()\n",
    "\n",
    "        if existing_id:\n",
    "            postprocess_step_id = existing_id[0]\n",
    "        else:\n",
    "            # Insert data into POSTPROCESS_STEP table\n",
    "            cur.execute(\n",
    "                \"INSERT INTO POSTPROCESS_STEP (treatment_type, params, meta) VALUES (%s, %s::jsonb, %s::jsonb) RETURNING postprocess_step_id\",\n",
    "                (treatment_type, params, meta)\n",
    "            )\n",
    "            postprocess_step_id = cur.fetchone()[0]\n",
    "\n",
    "        return postprocess_step_id\n",
    "\n",
    "    # Function to insert data into POSTPROCESS_ORDER table\n",
    "    def insert_into_postprocess_order(cur, postprocess_id, process_order, postprocess_step_id):\n",
    "        # Check if the record already exists\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            SELECT postprocess_id\n",
    "            FROM POSTPROCESS_ORDER\n",
    "            WHERE postprocess_id = %s\n",
    "            AND process_order = %s\n",
    "            AND postprocess_step_id = %s\n",
    "            \"\"\",\n",
    "            (postprocess_id, process_order, postprocess_step_id)\n",
    "        )\n",
    "        existing_combination = cur.fetchone()\n",
    "\n",
    "        if not existing_combination:\n",
    "            # Insert new record into POSTPROCESS_ORDER table\n",
    "            cur.execute(\n",
    "                \"INSERT INTO POSTPROCESS_ORDER (postprocess_id, process_order, postprocess_step_id) VALUES (%s, %s, %s)\",\n",
    "                (postprocess_id, process_order, postprocess_step_id)\n",
    "            )\n",
    "\n",
    "        return postprocess_id\n",
    "\n",
    "    # Establish a connection to the PostgreSQL database\n",
    "    conn = psycopg2.connect(**param_dict)\n",
    "\n",
    "    # Create a cursor object to interact with the database\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    postprocess_id = None\n",
    "\n",
    "    for treatment in post_process.values():\n",
    "        # Convert params and meta to JSON format\n",
    "        params_json = json.dumps(treatment.get('params', {}))\n",
    "        meta_json = json.dumps(treatment.get('meta', {}))\n",
    "\n",
    "        # Insert data into POSTPROCESS_STEP table\n",
    "        postprocess_step_id = insert_into_postprocess_step(cur, treatment['treatment_type'], params_json, meta_json)\n",
    "\n",
    "        if postprocess_id is None:\n",
    "            # Check if the record already exists in POSTPROCESS table\n",
    "            cur.execute(\n",
    "                \"SELECT postprocess_id FROM POSTPROCESS WHERE postprocess_id IN (SELECT postprocess_id FROM POSTPROCESS_ORDER WHERE postprocess_step_id = %s)\",\n",
    "                (postprocess_step_id,)\n",
    "            )\n",
    "            existing_id = cur.fetchone()\n",
    "\n",
    "            if existing_id:\n",
    "                postprocess_id = existing_id[0]\n",
    "            else:\n",
    "                # Insert data into POSTPROCESS table\n",
    "                cur.execute(\n",
    "                    \"INSERT INTO POSTPROCESS (postprocess_id) VALUES (DEFAULT) RETURNING postprocess_id\"\n",
    "                )\n",
    "                postprocess_id = cur.fetchone()[0]\n",
    "\n",
    "        # Insert data into POSTPROCESS_ORDER table\n",
    "        postprocess_id = insert_into_postprocess_order(cur, postprocess_id, treatment['process_step'], postprocess_step_id)\n",
    "\n",
    "    # Commit the changes to the database\n",
    "    print(\"Post Process treatment saved successfully with id : {}\".format(postprocess_id))\n",
    "    conn.commit()\n",
    "\n",
    "    # Close the cursor and connection\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "### 7. Checking and Storing information to the SAMPLE TABLE and generating sample_id\n",
    "def insert_into_sample_table(pg_query, sample_columns, sample_values):\n",
    "    sql = '''\n",
    "        INSERT INTO sample (%s) \n",
    "        VALUES %s\n",
    "        ON CONFLICT (exp_id, process_id) DO UPDATE\n",
    "        SET (%s) = %s\n",
    "        RETURNING sample_id\n",
    "        '''\n",
    "\n",
    "    tup = (AsIs(','.join(sample_columns)), tuple(sample_values), AsIs(','.join(sample_columns)), tuple(sample_values))\n",
    "\n",
    "    sample_id = pg_query(sql, tup)\n",
    "    print(\"sample_id is: {}\".format(sample_id))\n",
    "\n",
    "# Usage\n",
    "sample_columns = ['exp_id', 'process_id']\n",
    "sample_values = [exp_id, process_id]\n",
    "\n",
    "insert_into_sample_table(pg_query, sample_columns, sample_values)\n",
    "\n",
    "### 8. Checking and Storing the measurement information \n",
    "#### 8.1 Storing Device Measurement Information \n",
    "def insert_into_measurement_table(pg_query, sample_id, device_meas_columns, device_meas_values):\n",
    "    device_meas_columns_list = list(device_meas_columns)  # Convert dict_keys to a list\n",
    "    device_meas_columns_list.insert(0, 'sample_id')\n",
    "    device_meas_values.insert(0, sample_id)\n",
    "\n",
    "    # If meta information is missing\n",
    "    if 'meta' not in device_meas_columns_list:\n",
    "        device_meas_columns_list.append('meta')\n",
    "        device_meas_values.append({})\n",
    "\n",
    "    device_meas_values = [json.dumps(value) if isinstance(value, dict) else value for value in device_meas_values]\n",
    "\n",
    "    sql = '''\n",
    "        INSERT INTO measurement (%s) \n",
    "        VALUES %s\n",
    "        ON CONFLICT (sample_id, measurement_type, data, meta) DO UPDATE\n",
    "        SET (%s) = %s\n",
    "        RETURNING measurement_id\n",
    "        '''\n",
    "\n",
    "    tup = (\n",
    "        AsIs(','.join(device_meas_columns_list)),\n",
    "        tuple(device_meas_values),\n",
    "        AsIs(','.join(device_meas_columns_list)),\n",
    "        tuple(device_meas_values)\n",
    "    )\n",
    "\n",
    "    measurement_id = pg_query(sql, tup)\n",
    "    print(\"device measurement information saved successfully with id: {}\".format(measurement_id))\n",
    "\n",
    "# Usage\n",
    "sample_id = ...  # Provide the sample_id value\n",
    "device_meas_columns = device_meas_pg_entry\n",
    "device_meas_values = device_meas_values\n",
    "\n",
    "insert_into_measurement_table(pg_query, sample_id, device_meas_columns, device_meas_values)\n",
    "\n",
    "\n",
    "#### 8.2 Storing Other Measurement Information \n",
    "def insert_other_meas_into_measurement_table(pg_query, sample_id, other_meas):\n",
    "    for items in other_meas:\n",
    "        other_meas_pg_entry, other_meas_columns, other_meas_values = convert_entry(other_meas[items])\n",
    "\n",
    "        other_meas_columns_list = list(other_meas_columns)  # Convert dict_keys to a list\n",
    "        other_meas_columns_list.insert(0, 'sample_id')\n",
    "        other_meas_values.insert(0, sample_id)\n",
    "\n",
    "        # If meta information is missing\n",
    "        if 'meta' not in other_meas_columns_list:\n",
    "            other_meas_columns_list.append('meta')\n",
    "            other_meas_values.append({})\n",
    "\n",
    "        other_meas_values = [json.dumps(value) if isinstance(value, dict) else value for value in other_meas_values]\n",
    "\n",
    "        sql = '''\n",
    "        INSERT INTO measurement (%s) \n",
    "        VALUES %s\n",
    "        ON CONFLICT (sample_id, measurement_type, data, meta) DO UPDATE\n",
    "        SET (%s) = %s\n",
    "        RETURNING measurement_id\n",
    "        '''\n",
    "\n",
    "        tup = (\n",
    "            AsIs(','.join(other_meas_columns_list)),\n",
    "            tuple(other_meas_values),\n",
    "            AsIs(','.join(other_meas_columns_list)),\n",
    "            tuple(other_meas_values)\n",
    "        )\n",
    "\n",
    "        measurement_id = pg_query(sql, tup)\n",
    "        print(\"other measurement information saved successfully with id: {}\".format(measurement_id))\n",
    "\n",
    "# Usage\n",
    "sample_id = ...  # Provide the sample_id value\n",
    "other_meas = ...  # Provide the other_meas dictionary\n",
    "\n",
    "insert_other_meas_into_measurement_table(pg_query, sample_id, other_meas)\n",
    "\n",
    "\n",
    "print(\"Record stored successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39ccb45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "f5a8b522aac8123589db0e64c73ca2530e0ffae51a117df4f813e361992c41db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
